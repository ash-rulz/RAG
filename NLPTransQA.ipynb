{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNAdgP6IiuOHuA+zubmMlLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8415b74ae444c088859b710f4c33b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42ab336ea07942cea3262a79b763dc16",
              "IPY_MODEL_6bb89cca1cf84a089d3c34a9991f2525",
              "IPY_MODEL_df928022468a4d6b8b34226381c47cbf"
            ],
            "layout": "IPY_MODEL_ea748a9849644a45a11730f3224a29d7"
          }
        },
        "42ab336ea07942cea3262a79b763dc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b49162f9c48c4619ab291888f211f920",
            "placeholder": "​",
            "style": "IPY_MODEL_f8225eafa99843d88cd043feb8433f56",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6bb89cca1cf84a089d3c34a9991f2525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd2631c7c4f74664b212dbc9046048a8",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_447579c2ed8d40f59246dff141aaa352",
            "value": 28
          }
        },
        "df928022468a4d6b8b34226381c47cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9efc55ad93de4fa8aa0cf1727a488f92",
            "placeholder": "​",
            "style": "IPY_MODEL_ab129e5cec5d41fab7b990625fdc04a1",
            "value": " 28.0/28.0 [00:00&lt;00:00, 679B/s]"
          }
        },
        "ea748a9849644a45a11730f3224a29d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b49162f9c48c4619ab291888f211f920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8225eafa99843d88cd043feb8433f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd2631c7c4f74664b212dbc9046048a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447579c2ed8d40f59246dff141aaa352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9efc55ad93de4fa8aa0cf1727a488f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab129e5cec5d41fab7b990625fdc04a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09c770df98ee4571be62a88ce057b53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bb84a965c3547ed9e8aa15392955eb9",
              "IPY_MODEL_ebfc2b6cc2b6472baf9c07226324061b",
              "IPY_MODEL_c6fbdb33cfdd4697ae35bd91719d3c1f"
            ],
            "layout": "IPY_MODEL_0471622ca1bf4fb38d62e53acb3d4f6c"
          }
        },
        "8bb84a965c3547ed9e8aa15392955eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff6ae509af44561aec3d4171341864e",
            "placeholder": "​",
            "style": "IPY_MODEL_b078f47fc26d4b188b0281af97eba1ac",
            "value": "config.json: 100%"
          }
        },
        "ebfc2b6cc2b6472baf9c07226324061b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59006a41b744768990488d24176ba37",
            "max": 493,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bc161fec7134d749058dd2727ff125c",
            "value": 493
          }
        },
        "c6fbdb33cfdd4697ae35bd91719d3c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd0993e606d74f22a862ac7ae352c7bb",
            "placeholder": "​",
            "style": "IPY_MODEL_50db288ee37a41eea8088f3ee85b0e9b",
            "value": " 493/493 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "0471622ca1bf4fb38d62e53acb3d4f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff6ae509af44561aec3d4171341864e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b078f47fc26d4b188b0281af97eba1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a59006a41b744768990488d24176ba37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc161fec7134d749058dd2727ff125c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd0993e606d74f22a862ac7ae352c7bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50db288ee37a41eea8088f3ee85b0e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "062cfcec2539480aab0c7d7ad428d505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_451f6ddd5aa74d2f9e5d6f09fcfbf8d1",
              "IPY_MODEL_0baa1b085f214dd38c94f1d33525adaa",
              "IPY_MODEL_f0b2407aaae647a386e059451f88daab"
            ],
            "layout": "IPY_MODEL_e446039e58d0407c9df8f9207938fe2f"
          }
        },
        "451f6ddd5aa74d2f9e5d6f09fcfbf8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d32a54148b4ae68aee0ffa500213d9",
            "placeholder": "​",
            "style": "IPY_MODEL_fe56d408a27741a99b743757e3b956e7",
            "value": "vocab.txt: 100%"
          }
        },
        "0baa1b085f214dd38c94f1d33525adaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5351b55dcb5b4b0abd69ecbbd038ba79",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_562ca17908ee4af2874f5143a33a9da0",
            "value": 231508
          }
        },
        "f0b2407aaae647a386e059451f88daab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f69835c2184d0088bfa26b8134b9ce",
            "placeholder": "​",
            "style": "IPY_MODEL_2df5dc79cbb44c61ab0953ac08ea398c",
            "value": " 232k/232k [00:00&lt;00:00, 3.45MB/s]"
          }
        },
        "e446039e58d0407c9df8f9207938fe2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d32a54148b4ae68aee0ffa500213d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe56d408a27741a99b743757e3b956e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5351b55dcb5b4b0abd69ecbbd038ba79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562ca17908ee4af2874f5143a33a9da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7f69835c2184d0088bfa26b8134b9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df5dc79cbb44c61ab0953ac08ea398c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9896ee9fc84073b699fd820bef4f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19c935774bb44379aaa6da596af3a1ed",
              "IPY_MODEL_407336f3d7074ee8ae18fc5fbc342998",
              "IPY_MODEL_1a6672156fc1428aa1537db60f34fa75"
            ],
            "layout": "IPY_MODEL_60edfc0dbce04f92a5f87adee5685117"
          }
        },
        "19c935774bb44379aaa6da596af3a1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a922421d75a4df0893cf102f01666ff",
            "placeholder": "​",
            "style": "IPY_MODEL_4e64f4a970d8473a85c9ef6d45eb6bf4",
            "value": "tokenizer.json: 100%"
          }
        },
        "407336f3d7074ee8ae18fc5fbc342998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df1a70c9c3741e9a4ce7c2e7b046278",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cb29a3f85eb4f04a34425217af1d854",
            "value": 466062
          }
        },
        "1a6672156fc1428aa1537db60f34fa75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b47dec898a499c99c7b0ac79b5e035",
            "placeholder": "​",
            "style": "IPY_MODEL_38b90803b2554a86a7d2ddc5d416e757",
            "value": " 466k/466k [00:00&lt;00:00, 6.70MB/s]"
          }
        },
        "60edfc0dbce04f92a5f87adee5685117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a922421d75a4df0893cf102f01666ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e64f4a970d8473a85c9ef6d45eb6bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7df1a70c9c3741e9a4ce7c2e7b046278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb29a3f85eb4f04a34425217af1d854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21b47dec898a499c99c7b0ac79b5e035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b90803b2554a86a7d2ddc5d416e757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b284689026da43b1b6f1be6eeb991259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a49a496335b49788a4690d7b512fa0b",
              "IPY_MODEL_c784febbb7e248dfbc013cf1ffed92fd",
              "IPY_MODEL_973464c9358f4a869ae9c022b2af0d84"
            ],
            "layout": "IPY_MODEL_efae5832bac84d488811ebe144a8af55"
          }
        },
        "0a49a496335b49788a4690d7b512fa0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0903341dd13d47e8ba96326ac84314da",
            "placeholder": "​",
            "style": "IPY_MODEL_53a1f77bdac54368afa154142d8089bc",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c784febbb7e248dfbc013cf1ffed92fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_188f4d451f274040b2fbcd62fd542ee9",
            "max": 437986065,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8109354217254a0fadb6464cb03435b0",
            "value": 437986065
          }
        },
        "973464c9358f4a869ae9c022b2af0d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0055bfcc81ad473c9bd6f0f77f3473ac",
            "placeholder": "​",
            "style": "IPY_MODEL_a3a2879572a04a0db8da3d725f5b4977",
            "value": " 438M/438M [00:04&lt;00:00, 198MB/s]"
          }
        },
        "efae5832bac84d488811ebe144a8af55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0903341dd13d47e8ba96326ac84314da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a1f77bdac54368afa154142d8089bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188f4d451f274040b2fbcd62fd542ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8109354217254a0fadb6464cb03435b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0055bfcc81ad473c9bd6f0f77f3473ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a2879572a04a0db8da3d725f5b4977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be03d56f67ab4fb4b14fae4ea8553edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da4f6de24d294b60b7b89908306d586d",
              "IPY_MODEL_1eeb3f38e32247869442f2638b75c208",
              "IPY_MODEL_3fbb172b83db40279bf4e74e9c997731"
            ],
            "layout": "IPY_MODEL_7a952f046e4d4875a33fa2b01710e550"
          }
        },
        "da4f6de24d294b60b7b89908306d586d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cd43461df04732a9da02a3094144a0",
            "placeholder": "​",
            "style": "IPY_MODEL_999bcbee10784e5780dd61b29416b14f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1eeb3f38e32247869442f2638b75c208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444fd01416d043ec90938f065ad7eb03",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cffbdd2895e6499dbd523758bd7f3c58",
            "value": 28
          }
        },
        "3fbb172b83db40279bf4e74e9c997731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246c42115f1e431784da632040d05cce",
            "placeholder": "​",
            "style": "IPY_MODEL_fa0e0ca307e847afac9cc57be45c5c96",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.05kB/s]"
          }
        },
        "7a952f046e4d4875a33fa2b01710e550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cd43461df04732a9da02a3094144a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999bcbee10784e5780dd61b29416b14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "444fd01416d043ec90938f065ad7eb03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffbdd2895e6499dbd523758bd7f3c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "246c42115f1e431784da632040d05cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0e0ca307e847afac9cc57be45c5c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e1dcfd4c744909b286c0876466951e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_652ea54932c34897a9a4c2e0d6450f80",
              "IPY_MODEL_acbfe4c2162340fe8a133f08cea736a9",
              "IPY_MODEL_4a82a2103dd044eb8ac2202e99909f16"
            ],
            "layout": "IPY_MODEL_1752ce80bc204fceabfa2dedd9d83dbf"
          }
        },
        "652ea54932c34897a9a4c2e0d6450f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1094022a864849e3a41584fbcfe24366",
            "placeholder": "​",
            "style": "IPY_MODEL_a3feb58f35b14340bcede3d8468fec70",
            "value": "config.json: 100%"
          }
        },
        "acbfe4c2162340fe8a133f08cea736a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518818d243a541e8ba23f56acda83ab7",
            "max": 492,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4fae264f3a84e0abbc72d0488f0fb8d",
            "value": 492
          }
        },
        "4a82a2103dd044eb8ac2202e99909f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561db3d1b90347d6a5492e2c5dc3b39c",
            "placeholder": "​",
            "style": "IPY_MODEL_b8c9dc106023427a892217ab76a835e6",
            "value": " 492/492 [00:00&lt;00:00, 33.0kB/s]"
          }
        },
        "1752ce80bc204fceabfa2dedd9d83dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1094022a864849e3a41584fbcfe24366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3feb58f35b14340bcede3d8468fec70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "518818d243a541e8ba23f56acda83ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4fae264f3a84e0abbc72d0488f0fb8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "561db3d1b90347d6a5492e2c5dc3b39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c9dc106023427a892217ab76a835e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63b3a88d857048c19966499f614ba7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34a0788a00b64dae8741579dd95dcc2d",
              "IPY_MODEL_a938a883aaae459aaba727e3c28e9480",
              "IPY_MODEL_523bd6f64e744f269658f6d9d8b706dc"
            ],
            "layout": "IPY_MODEL_47c6364b0fb14166bf1e97c1feaf2d0b"
          }
        },
        "34a0788a00b64dae8741579dd95dcc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8918afa7aa94906a81f1c8470674375",
            "placeholder": "​",
            "style": "IPY_MODEL_a0817d00016b4cab8dcc21e3e9053261",
            "value": "vocab.txt: 100%"
          }
        },
        "a938a883aaae459aaba727e3c28e9480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29f76d2ca4724f2f9cd1765329fe123e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_883e5b48bcb04549b63ec640d85e6c55",
            "value": 231508
          }
        },
        "523bd6f64e744f269658f6d9d8b706dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb82ebdb3e9d44f8bd261be9039be2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_687b02a7da8a469fa384305620c99959",
            "value": " 232k/232k [00:00&lt;00:00, 10.7MB/s]"
          }
        },
        "47c6364b0fb14166bf1e97c1feaf2d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8918afa7aa94906a81f1c8470674375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0817d00016b4cab8dcc21e3e9053261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29f76d2ca4724f2f9cd1765329fe123e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883e5b48bcb04549b63ec640d85e6c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb82ebdb3e9d44f8bd261be9039be2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687b02a7da8a469fa384305620c99959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "845c5b13561e448f99501c6bfc73cb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f39d72d095f34805af501c1416698461",
              "IPY_MODEL_6090ecff667746dea0fe3e7a1d7be0fb",
              "IPY_MODEL_bcc23a3aca644b3ba3a3e4539df738b1"
            ],
            "layout": "IPY_MODEL_0f99103ffeff47afb745a70a83dd8e9d"
          }
        },
        "f39d72d095f34805af501c1416698461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5b1d2dcf9d5481ca43fb64155a3dae9",
            "placeholder": "​",
            "style": "IPY_MODEL_c6113d737ca84db990ffd2816590e7ee",
            "value": "tokenizer.json: 100%"
          }
        },
        "6090ecff667746dea0fe3e7a1d7be0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3833101859449ea7c9f905cb161ef0",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39c9419f24e14e1eb83c8c447754e86a",
            "value": 466062
          }
        },
        "bcc23a3aca644b3ba3a3e4539df738b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55457bcc54b1481f86538dd991f7517c",
            "placeholder": "​",
            "style": "IPY_MODEL_42878780caec48cba598b6bca3817ff6",
            "value": " 466k/466k [00:00&lt;00:00, 6.88MB/s]"
          }
        },
        "0f99103ffeff47afb745a70a83dd8e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b1d2dcf9d5481ca43fb64155a3dae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6113d737ca84db990ffd2816590e7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b3833101859449ea7c9f905cb161ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c9419f24e14e1eb83c8c447754e86a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55457bcc54b1481f86538dd991f7517c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42878780caec48cba598b6bca3817ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec58bc8306c346d7b9840708b35365e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2569729b21af43feb3ff75408e5cf53c",
              "IPY_MODEL_bb6f85111351467d9ac87d67161775ac",
              "IPY_MODEL_a8a1f4b7ff9f456baf02eeb0985bcc9f"
            ],
            "layout": "IPY_MODEL_38ae7fa119c546e2843533ebacc138eb"
          }
        },
        "2569729b21af43feb3ff75408e5cf53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82682cafa3eb41f59a1841b6126a8691",
            "placeholder": "​",
            "style": "IPY_MODEL_140971a99e4346eb9d3570b571765b76",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "bb6f85111351467d9ac87d67161775ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3541cc05b952463e9fd915ede6123687",
            "max": 437983985,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13577ea053544119800b7779d2b6394e",
            "value": 437983985
          }
        },
        "a8a1f4b7ff9f456baf02eeb0985bcc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a994dad0bb40a8a931721241f5675c",
            "placeholder": "​",
            "style": "IPY_MODEL_c34f8de64c78447aa293a531f16ff7fe",
            "value": " 438M/438M [00:02&lt;00:00, 214MB/s]"
          }
        },
        "38ae7fa119c546e2843533ebacc138eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82682cafa3eb41f59a1841b6126a8691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140971a99e4346eb9d3570b571765b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3541cc05b952463e9fd915ede6123687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13577ea053544119800b7779d2b6394e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05a994dad0bb40a8a931721241f5675c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34f8de64c78447aa293a531f16ff7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ash-rulz/RAG/blob/main/NLPTransQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering(QA)\n",
        "\n",
        "\n",
        "*   Extractive QA: Answers can be identified using span of text in a document\n",
        "*   Community QA: Involves gathering QA pairs from user forums like Stack-Overflow\n",
        "* Long-form QA: Generates complex paragraph-length answers\n"
      ],
      "metadata": {
        "id": "ZpTsNniDzGWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Answers from Text"
      ],
      "metadata": {
        "id": "J7WaHvy-zF3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Span classification task\n",
        "Model needs to predict the start and end tokens of an answer span.\n",
        "\n",
        "If the training set is small, use a [language model](https://huggingface.co/models?pipeline_tag=question-answering&search=squad).  that is fine-tuned on large-scale QA dataset like SQuAD."
      ],
      "metadata": {
        "id": "FzbFEZ3oKdMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization text for QA\n",
        "Use [minilm](https://huggingface.co/deepset/minilm-uncased-squad2) with 33.4M params for tokenization. [Paper](https://arxiv.org/abs/2002.10957)"
      ],
      "metadata": {
        "id": "7QPBs4nBKgrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "#Load the model with the frozen parameters\n",
        "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "kNp2UtTo30pV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample question and context to tokenize\n",
        "question = \"How much music can this hold?\"\n",
        "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\n",
        "file size.\"\"\"\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\") #Returns as a pytorch tensor"
      ],
      "metadata": {
        "id": "kOknbgna6JRv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36ba_UD8KoY",
        "outputId": "bcd12e0d-ec07-44bd-8fd7-6c1e689ec9d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2129,  2172,  2189,  2064,  2023,  2907,  1029,   102,  2019,\n",
              "         23378,  2003,  2055,  1015, 16914,  1013,  3371,  1010,  2061,  2055,\n",
              "         25961,  2847,  5834,  2006,  5371,  2946,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "token_type_ids: Which part is question and context?\n",
        "\n",
        "attention_mask: Allows the model to focus on the relevant parts of the text, in this case both the question and context."
      ],
      "metadata": {
        "id": "F9LMCPSa8Z3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode back the text using the input_ids\n",
        "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azfh9m6981U0",
        "outputId": "eded1e77-f8db-4d54-d36a-3579cdfbdf82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the model with QA head and do forward pass\n",
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)#Use the same model minilm as we used in tokenizer\n",
        "\n",
        "#We need to disable gradient tracking as this is inference and not training. Gradient tracking is a feature of PyTorch that is used for training models.\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf5Cw0Z49PnE",
        "outputId": "9adb7628-f9a3-49e2-9503-9f4498819354"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n",
            "         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n",
            "         -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,\n",
            "         -2.3108, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n",
            "         -0.9623, -3.7855, -0.8715, -3.7745, -3.0161, -1.1780,  0.1758, -2.7365,\n",
            "          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n",
            "         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further information for gradient tracking in pytorch can be obtained from [autograd](https://www.youtube.com/watch?v=DbeIqrwb_dE)"
      ],
      "metadata": {
        "id": "8_HEczfNIdFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "print(f\"Input IDs shape: {inputs.input_ids.size()}\")\n",
        "print(f\"Start logits shape: {start_logits.size()}\")\n",
        "print(f\"End logits shape: {end_logits.size()}\")\n",
        "#There are as many logits as there are inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGBIZHEd-puQ",
        "outputId": "1468c0d0-c6f7-4a3d-b090-8b64aa69066f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs shape: torch.Size([1, 28])\n",
            "Start logits shape: torch.Size([1, 28])\n",
            "End logits shape: torch.Size([1, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the answer from the logits\n",
        "start_idx = torch.argmax(start_logits)#Gets the start span\n",
        "end_idx = torch.argmax(end_logits) + 1#Gets the end span\n",
        "\n",
        "#Gets the answer and decodes it\n",
        "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
        "answer = tokenizer.decode(answer_span)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I1AndFc_N8_",
        "outputId": "8361901a-68d3-48f1-f9cf-f35fb0fddf02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How much music can this hold?\n",
            "Answer: 6000 hours\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All this can be wrapped in a dedicated pipeline:"
      ],
      "metadata": {
        "id": "1hjnbVhsI9TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "pipe(question=question, context=context, top_k =3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSbWYsh0JI3d",
        "outputId": "9afb00ee-14e0-4f47-a7f8-8fc325678e4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2651607394218445, 'start': 38, 'end': 48, 'answer': '6000 hours'},\n",
              " {'score': 0.2208300530910492,\n",
              "  'start': 16,\n",
              "  'end': 48,\n",
              "  'answer': '1 MB/minute, so about 6000 hours'},\n",
              " {'score': 0.10253580659627914,\n",
              "  'start': 16,\n",
              "  'end': 27,\n",
              "  'answer': '1 MB/minute'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will give multiple answers for the same question with different scores. If the model is not able to find the right answer, the start and end wuld point to the [CLS] token"
      ],
      "metadata": {
        "id": "PreFpaQkJv-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with long passages\n",
        "\n",
        "For tasks like text classification we could use [CLS], but for QA we would need to use *sliding window*. For the same question, slide the context bar across the window:\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "rjhXbAAvKTZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use this technique in the tokenizer function.\n",
        "\n",
        "\n",
        "```\n",
        "#Enables the sliding window\n",
        "return_overflowing_tokens=True\n",
        "```\n",
        "\n",
        "```\n",
        "#Size of the sliding window\n",
        "max_seq_length\n",
        "```\n",
        "\n",
        "```\n",
        "#Size of the stride\n",
        "doc_stride\n",
        "```\n"
      ],
      "metadata": {
        "id": "5J_typwyK8Js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The windows will overlap."
      ],
      "metadata": {
        "id": "HO01usTYFBws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Haystack to Build a QA Pipeline"
      ],
      "metadata": {
        "id": "9fuOaxY6FPJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QA systems are based on the **retriever-reader architecture**.\n",
        "\n",
        "*Retriever*\n",
        "Retrieves the relevant documents for the query. 2 types:\n",
        "1.   *Sparse Retrievers*: Documents and query is represented by word frequencies, like TF-IDF & BM25.\n",
        "2.   *Dense Retrievers*: Documents and query are converted to contexturalized embeddings using encoders, like Embedding and DPR(Dense Passage Retriever).\n",
        "\n",
        "*Reader*\n",
        "Extracts the answers from the documents. This is usually a *reading-comprehension model*.\n",
        "\n",
        "Document post-procession like re-ranking retrieved documents and Answer post-processing like cherry-picking the answers from various passages from a long document."
      ],
      "metadata": {
        "id": "ixTu1r4NFWcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to a Retriever and Reader, a Document store and a pipeline is required. For document store, Elasticsearch is used and for the pipeline Haystack is used."
      ],
      "metadata": {
        "id": "ssmkXR76IAPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Initializing a document store"
      ],
      "metadata": {
        "id": "irgMrgZ1WAis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Haystack's document store expects a list of dictionaries of the form:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "It is not text, it should be content. See [write_documents documentation](https://colab.research.google.com/drive/1UHkxej4EkFz0lhr9FIAomvcaY7T-VtOT#scrollTo=Xr80Z8DQn3Uk&line=4&uniqifier=1) for the correct implementation.\n",
        "\n",
        "meta can be used for applying filters during retrievals.\n"
      ],
      "metadata": {
        "id": "Xr80Z8DQn3Uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will store the data from [subjqa](https://huggingface.co/datasets/subjqa)"
      ],
      "metadata": {
        "id": "QpQSe8Y2oriu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "JY_lsYugpaRn",
        "outputId": "fe1a1522-f44e-4875-90fd-40823187eaf2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Collecting huggingface-hub>=0.18.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.19.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "subjqa = load_dataset(\"subjqa\", name=\"electronics\")"
      ],
      "metadata": {
        "id": "KLuWyXWDVls2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjqa['train']['answers'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKlG4O8RqUA6",
        "outputId": "ae52d8fb-644e-489f-bf32-a91582e06b54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['Bass is weak as expected',\n",
              "  'Bass is weak as expected, even with EQ adjusted up'],\n",
              " 'answer_start': [1302, 1302],\n",
              " 'answer_subj_level': [1, 1],\n",
              " 'ans_subj_score': [0.5083333253860474, 0.5083333253860474],\n",
              " 'is_ans_subjective': [True, True]}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Flatten the dataset\n",
        "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}"
      ],
      "metadata": {
        "id": "9NvGkGEZqChR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will install elastisearch and load the data ito the document store using haystack pipeline. See [documenatation for implementation](https://haystack.deepset.ai/tutorials/03_scalable_qa_system)."
      ],
      "metadata": {
        "id": "RsSLo4_s_WxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,preprocessing,elasticsearch,inference]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qizkShFL2q7s",
        "outputId": "5a3ad4f9-424a-4f45-b1cf-416cb85b7b3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "Requirement already satisfied: farm-haystack[colab,elasticsearch,inference,preprocessing] in /usr/local/lib/python3.10/dist-packages (1.22.1)\n",
            "Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.0.7)\n",
            "Requirement already satisfied: events in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.25.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.19.2)\n",
            "Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (9.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.11.0)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.1.0)\n",
            "Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.0.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.10.13)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.9.0)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.31.0)\n",
            "Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.9.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.3.2)\n",
            "Requirement already satisfied: sseclient-py in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.8.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.66.1)\n",
            "Requirement already satisfied: transformers==4.34.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.34.1)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.0.9)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.19.4)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.2.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,elasticsearch,inference,preprocessing]) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.4.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.25.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (23.1.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (23.2.3)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.4.3)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.16.0+cu118)\n",
            "Requirement already satisfied: elastic-transport<8 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (7.16.0)\n",
            "Requirement already satisfied: elasticsearch<8,>=7.17 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (7.17.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.13.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->farm-haystack[colab,elasticsearch,inference,preprocessing]) (8.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2023.3.post1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (7.0.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.5.13)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (5.9.5)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.2.0)\n",
            "Collecting huggingface-hub>=0.5.0 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
            "  Using cached huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.1.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->quantulum3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.34.1; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.3.0)\n",
            "Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "Successfully installed huggingface-hub-0.17.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "metadata": {
        "id": "QkE5S_KP2bSQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "metadata": {
        "id": "amxjg4Ob8Ru5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "time.sleep(30)"
      ],
      "metadata": {
        "id": "vaIZtIVe8V1P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confirm whether Elasticseach is running\n",
        "!curl -X GET \"localhost:9200/?pretty\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhjmpQXC9WoW",
        "outputId": "1c28bb30-d341-4265-96a0-f59c60706aef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"763d07daa9dc\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"7SjTisvuSjO0VMnCc9Ah8A\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"default\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n",
        "# Get the host where Elasticsearch is running, default to localhost\n",
        "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
        "\n",
        "# Return the document embedding for later use with dense retriever\n",
        "document_store = ElasticsearchDocumentStore(return_embedding=True)"
      ],
      "metadata": {
        "id": "awXNihbw8ixT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for split, df in dfs.items():\n",
        "\t# Exclude duplicate reviews\n",
        "\tdocs = [{\"content\": row[\"context\"],\n",
        "\t\t\t\"meta\":{\"item_id\": row[\"title\"], \"question_id\": row[\"id\"],\n",
        "\t\t\t\"split\": split}}\n",
        "\t\tfor _,row in df.drop_duplicates(subset=\"context\").iterrows()]\n",
        "\tdocument_store.write_documents(docs, index=\"document\")\n",
        "print(f\"Loaded {document_store.get_document_count()} documents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QFZm_xdrDK6",
        "outputId": "59a831d0-c5c4-44d2-e54f-c14b43073eb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1615 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ElasticsearchDocumentStore has 2 indices:\n",
        "\n",
        "\n",
        "1. *document* for storing the documents\n",
        "2. *[label](https://colab.research.google.com/drive/1UHkxej4EkFz0lhr9FIAomvcaY7T-VtOT#scrollTo=zLuJ_HjYNtx7&line=7&uniqifier=1)* for storing the annotated answer spans\n",
        "\n",
        "In the above implementation, we have only stored the reviews in the document index.\n",
        "\n"
      ],
      "metadata": {
        "id": "lCcUyKtB_5HY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing a retriever\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "E6aSYyPbBgLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "es_retriever = BM25Retriever(document_store=document_store)"
      ],
      "metadata": {
        "id": "iNmIsXCeByEe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_id = \"B0074BW614\"\n",
        "query = \"Is it good for reading?\"\n",
        "retrieved_docs = es_retriever.retrieve(\n",
        "  query=query, top_k=3, filters={\"item_id\":[item_id], \"split\":[\"train\"]})"
      ],
      "metadata": {
        "id": "p4cxirBdCJyG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S23LPlxD4to",
        "outputId": "fe16c217-0912-4c47-da77-7ea8733fc0aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Document: {'content': 'This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my laptop, my phone and my iPod classic.  I love my iPod but watching movies on the plane with it can be challenging because it is so small. Laptops battery life is not as good as the Kindle.  So the Fire combines for me what I needed all three to do. So far so good.', 'content_type': 'text', 'score': 0.6857824513476455, 'meta': {'item_id': 'B0074BW614', 'question_id': '868e311275e26dbafe5af70774a300f3', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '252e83e25d52df7311d597dc89eef9f6'}>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we ask a question about a particular product. This is why we use meta to filter out documents. The result also gives how relevant this document is by the score field. Checking the score for the next document."
      ],
      "metadata": {
        "id": "xBdowTZ4EFm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0TthIyJD8AL",
        "outputId": "f0392266-3063-42f1-a5b3-3c8e433e92c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Document: {'content': 'Plays Netflix great, WiFi capability has great range. Resolution on the screen is AMAZING! For the price you cannot go wrong. Bought one for my spouse and myself after becoming addicted to hers! Our son LOVES it and it is great for reading books when no light is available. Amazing sound but I suggest good headphones to really hear it all.Battery life is super long and can go 3 or 4 days without a recharge from moderate use.A steal at $199.99.', 'content_type': 'text', 'score': 0.6846554055365114, 'meta': {'item_id': 'B0074BW614', 'question_id': '998d564607f10bf6dbbd20b33b8fbbf1', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '41f4a1710c6f3be65c7814326b662ab6'}>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing a reader\n",
        "The reader is used to extract the answers from the retrieved documents."
      ],
      "metadata": {
        "id": "cYqSF6C5E_MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "max_seq_length, doc_stride = 384, 128\n",
        "reader = FARMReader(model_name_or_path=\"deepset/minilm-uncased-squad2\", use_gpu=True, max_seq_len=max_seq_length, doc_stride=doc_stride, return_no_answer=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GUYAMCLEuXj",
        "outputId": "c691f75e-b5c3-4708-b2e0-8649187c62ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'How much music can this hold?'\n",
        "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\n",
        "file size.\"\"\"\n",
        "print(reader.predict_on_texts(question=question, texts=[context], top_k=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqUvLClHGljm",
        "outputId": "1c06e439-eb42-4215-b3ca-d3a780a7bb88"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'How much music can this hold?', 'no_ans_gap': 12.64809501171112, 'answers': [<Answer {'answer': '6000 hours', 'type': 'extractive', 'score': 0.5293065905570984, 'context': 'An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.', 'offsets_in_document': [{'start': 38, 'end': 48}], 'offsets_in_context': [{'start': 38, 'end': 48}], 'document_ids': ['e344757014e804eff50faa3ecf1c9c75'], 'meta': {}}>]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above test shows that the reader is able to get the correct answer for the given question and the context."
      ],
      "metadata": {
        "id": "uAIeyCZwHhWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the haystack pipeline abstraction\n",
        "The pipeline will take the retriever, reader as input and provides an abstraction over this whole process."
      ],
      "metadata": {
        "id": "jyPrmbAqIFWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "querying_pipeline = Pipeline()\n",
        "querying_pipeline.add_node(component=es_retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
        "querying_pipeline.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])\n",
        "\n",
        "n_answers = 3\n",
        "prediction = querying_pipeline.run(\n",
        "    query=query, params={\"Retriever\": {\"top_k\": 3}, \"Reader\": {\"top_k\": n_answers},  \"filters\": {\n",
        "            \"item_id\": [item_id],\n",
        "            \"split\":[\"train\"]\n",
        "        }}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjQ08oYxF6go",
        "outputId": "45c57edb-e60d-4c5e-8d69-57971cf92a4e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.13 Batches/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWuZ-1nQJ4mI",
        "outputId": "85d9f0d5-0d82-41d9-b76d-32d73e81e503"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answers': [<Answer {'answer': 'it is great for reading books when no light is available', 'type': 'extractive', 'score': 0.5443062782287598, 'context': 'ecoming addicted to hers! Our son LOVES it and it is great for reading books when no light is available. Amazing sound but I suggest good headphones t', 'offsets_in_document': [{'start': 216, 'end': 272}], 'offsets_in_context': [{'start': 47, 'end': 103}], 'document_ids': ['41f4a1710c6f3be65c7814326b662ab6'], 'meta': {'item_id': 'B0074BW614', 'question_id': '998d564607f10bf6dbbd20b33b8fbbf1', 'split': 'train'}}>,\n",
            "             <Answer {'answer': 'I mainly use it for book reading', 'type': 'extractive', 'score': 0.469524621963501, 'context': ' is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my la', 'offsets_in_document': [{'start': 132, 'end': 164}], 'offsets_in_context': [{'start': 59, 'end': 91}], 'document_ids': ['252e83e25d52df7311d597dc89eef9f6'], 'meta': {'item_id': 'B0074BW614', 'question_id': '868e311275e26dbafe5af70774a300f3', 'split': 'train'}}>,\n",
            "             <Answer {'answer': '', 'type': 'extractive', 'score': 0.4553244090206485, 'context': None, 'offsets_in_document': [{'start': 0, 'end': 0}], 'offsets_in_context': [{'start': 0, 'end': 0}], 'document_ids': None, 'meta': {}}>],\n",
            " 'documents': [<Document: {'content': 'This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my laptop, my phone and my iPod classic.  I love my iPod but watching movies on the plane with it can be challenging because it is so small. Laptops battery life is not as good as the Kindle.  So the Fire combines for me what I needed all three to do. So far so good.', 'content_type': 'text', 'score': 0.6857824513476455, 'meta': {'item_id': 'B0074BW614', 'question_id': '868e311275e26dbafe5af70774a300f3', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '252e83e25d52df7311d597dc89eef9f6'}>,\n",
            "               <Document: {'content': 'Plays Netflix great, WiFi capability has great range. Resolution on the screen is AMAZING! For the price you cannot go wrong. Bought one for my spouse and myself after becoming addicted to hers! Our son LOVES it and it is great for reading books when no light is available. Amazing sound but I suggest good headphones to really hear it all.Battery life is super long and can go 3 or 4 days without a recharge from moderate use.A steal at $199.99.', 'content_type': 'text', 'score': 0.6846554055365114, 'meta': {'item_id': 'B0074BW614', 'question_id': '998d564607f10bf6dbbd20b33b8fbbf1', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '41f4a1710c6f3be65c7814326b662ab6'}>,\n",
            "               <Document: {'content': 'I\\'ve used an e-reader since the Rocket ebook in 1999, and I\\'ve always believed I wanted only an ebook reader with no other features. I don\\'t get out much, so my computer is convenient for everything else.I\\'ve had several Kindles and was happy with all of them, but I had recently played around with my brother\\'s tablet. When my last Kindle died, I decided to replace it with the Kindle Fire. I chose the smaller one because I was concerned about my arthritic hands holding a larger device for long periods. The 7\" is just perfect for me. It\\'s light enough that I can hold it to read, but the larger screen compared to the Kindle makes for easier reading. I love the color, something I never thought would make a difference to me.Oddly enough, high on my favorite list is the ability to review a book as soon as I reach the end. I have written reviews of every book I read on a readers social media site, but I have seldom put in the extra effort to come to Amazon to write a review. On the Kindle Fire, as soon as I come to the end of a book, a review page pops up so I can review it while it\\'s fresh on my mind, and I\\'m reviewing everything I read.I didn\\'t realize when I placed my order that I was ordering that the device had special offers. I\\'ve always thought I would not want to be subject to advertising when I was reading. However, I discovered that the special offers are discreet and no distraction at all. I\\'ve even found myself going to the special offers page a time or two to see what\\'s on offer.The only negative is that the battery doesn\\'t last very long. However, with the PowerFast charger, it doesn\\'t take long to charge the battery.I think folks like me who have always used a dedicated ereader and never even used a touch screen will be pleasantly surprised with the Kindle Fire, and people who are used to smartphones and tablets will find everything they expect in a device.Update 11/8/13: I still think the Kindle Fire is a fantastic product, and I use it occasionally for games. However, I have gone back to my Kindle Keyboard for reading novels. The arthritis in my shoulders, elbows, and hands has  worsened since I\\'ve been using the Kindle Fire, and even using the device for a short while increases the pain significantly. I can tolerate it for short periods to play a few games. However, I simply can\\'t hold the Kindle Fire long enough for reading. This won\\'t be an issue for most people, but I wanted to mention it for those people who might have similar problems.', 'content_type': 'text', 'score': 0.6578420310105324, 'meta': {'item_id': 'B0074BW614', 'question_id': '3ecfc76edee933ba1f202069b4fe7847', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '219ce93058383db5659102424e34a094'}>],\n",
            " 'no_ans_gap': 13.715797066688538,\n",
            " 'node_id': 'Reader',\n",
            " 'params': {'Reader': {'top_k': 3},\n",
            "            'Retriever': {'top_k': 3},\n",
            "            'filters': {'item_id': ['B0074BW614'], 'split': ['train']}},\n",
            " 'query': 'Is it good for reading?',\n",
            " 'root_node': 'Query'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import print_answers\n",
        "\n",
        "print_answers(prediction, details=\"minimum\")  ## Choose from `minimum`, `medium` and `all`\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKDDIAknJeVj",
        "outputId": "3e61e21c-882c-445f-d1f9-22ac362b4006"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Query: Is it good for reading?'\n",
            "'Answers:'\n",
            "[   {   'answer': 'it is great for reading books when no light is available',\n",
            "        'context': 'ecoming addicted to hers! Our son LOVES it and it is great '\n",
            "                   'for reading books when no light is available. Amazing '\n",
            "                   'sound but I suggest good headphones t'},\n",
            "    {   'answer': 'I mainly use it for book reading',\n",
            "        'context': ' is my third one.  I never thought I would want a fire for '\n",
            "                   'I mainly use it for book reading.  I decided to try the '\n",
            "                   'fire for when I travel I take my la'},\n",
            "    {'answer': ''}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving QA pipeline"
      ],
      "metadata": {
        "id": "cnKALE-yKWxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Retriever\n",
        "The retriever sets the upper bound of the performance of the QA system. Hence it is important to evaluate the retriever. A document is considered correctly retrieved if it contains the gold answer string within it."
      ],
      "metadata": {
        "id": "JOfi8a0rn6Ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation 1: Steps can be found [here](https://haystack.deepset.ai/tutorials/05_evaluation)"
      ],
      "metadata": {
        "id": "iYAhAU8yoLcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.set_option('display.max_colwidth', None)\n",
        "dfs[\"test\"].loc[0:5, [\"question\",\"context\", \"answers.text\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l_thmV_-2oda",
        "outputId": "d0b62c99-6cbd-4fb8-d77d-e914f939ff03"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                           question  \\\n",
              "0                                    What is the tonal balance of these headphones?   \n",
              "1  How would you describe the texture of the lens at all focal lengths above 150mm?   \n",
              "2                                                                 How is the thing?   \n",
              "3                                                         How do you like the lens?   \n",
              "4                                                              How is the contrast?   \n",
              "5                                         Is the cord safe to grab the transformer?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               context  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        UPDATED: 5/20/2011:  I used my D700, and only my 50mm F1.8 to capture my Grandson's first haircut!  I posted an image here.  And, on the way home following the haircut, a clearing storm brought some gorgeous bluish-black clouds at dusk so I swung down towards the river and shot a couple of shots with the 50mm.  I posted one here called \"Blue Hour\".  Enjoy.  Seriously, can't go wrong -- though the price seems to be creeping upwards...This 50mm 1.8 is an excellent purchase at around a hundred bucks.  I hate to use the word investment, because we know camera equipment is definitely NOT an investment.  I bought it because I heard so much about it, and, I had a 50mm back in my old film days.  I have not  been disappointed.  I will agree with  many here who say that at F1.8 the results are less than stellar.  This is true--- there is a lack of contrast, not necessarily sharpness (at least in my copy of the lens) that you will notice.  Since I know that as a fact going in to a shoot or session, I set my aperture at F2.0, or F2.2 on my D700, or D300.  This solves the problem.  The resulting images at F 2.0 and above are amazingly sharp, and clear.  Don't get me wrong, I love my 16-35F4VR, and my 24-70F2.8 but this 50mm rocks as a standalone lens when the situation demands fast lens.  As a matter of fact, in a few hours I'm heading off to my grandsons first haircut of his life.  What did I pack?  The D700 (for better high ISO performance than the D300), and my 50mm 1.8.For the price (which seems to have risen lately and rightly so) you can't go wrong.  Even if you have other zoom lenses that cover this range as I do, this lens is unbelievably useful in low light to no light situations.  Personally, I'm lazy and hate zooming with my feet, but I'd much rather do that with this lens, than either using flash, or blurring photos of important events.The lens finish is plasticy but so what?  Are you going to be banging it around on a regular basis?  My 50mm travels with me just about everywhere either in a camera bag, or in my North Face Recon backpack (not a camera backpack) just about everywhere, and I pump about 80,000 images a year per body, between landscapes, motorsports, portraits, etc.  So far, so good.  It does stand up to a beating.  I do not use any protective filter on it as the glass is relatively well recessed on this lens.When I do need to use filters such as polarizers, or ND's, I have step-up rings that take the lens from the 52mm size to 77mm which is the standard size of all my filters. It does look \"strange\" having the tiny little 50mm lens hidden behind a huge 77mm filter, but it WORKS.Again, if you are looking to make an investment -- there's that ugly word again, make that acquisition, to your photo gear you can't go wrong at this price point; If you wind up hating it, there's always the ability to return it, or sell it on eBay.Enjoy.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        It worked fine at the start but within a week individual ports ceased to function (so far 2).  Although I have populated all the ports most are not in constant use (Camera, GPS, Palm PDA, SD-reader).  Seems like this should be able to handle all of this.  Amazon replaced it but I'm still worried that the new one wont be any better.   \n",
              "3  I bought this lens for my Canon 20D digital camera and have found it to be a great all-purpose, everyday-use lens.  Here are the best features from my perspective:1.  The range of telephoto zoom is adequate for 90% of photo opportunites.  28-135 mm telephoto in digital photography translates into 48-230 mm in SLR film photography.  Since a standard camera lens is 50-55 mm, the starting range of this zoom lens equals that and then has the added versatility of zooming up to 135 mm (or 230mm in old style camera figures).  In my opinion, this added range of framing a shot gives the photographer so much more creativity, as well as being able to bring objects into closer, more intimate range.  I mentioned that this lens is good for 90% of all general camera shots; the missing 10% are those pictures that require a better zoom (more telephoto zoom), and those pics that need a wider field of view.  You may find that for group photos in close proximity, you want to take a step backwards to get everybody in the frame.  This is not a problem unless you simply don't have the room to take that step back.  I solved this problem by switching back to the original 18-55mm lens that came with the camera.  For the more distant shots that can't be drawn into the 135mm zoom of this lens I purchased a better telephoto zoom.2.  The lens has autofocus and IS stabilization technology.  For one used to manual focus lenses in SLR film photography, the addition of a fast autofocus lens is a terrific feature! I used to miss those spur of the moment shots because I was trying to achieve focus.  With this lens, you make those shots, because within a milisecond of depressing the shutter down halfway, the picture snaps into focus!  I absolutely love this feature!  The focuser has many points of potential focus, so it adapts easily to virtually all focusing situations.  For the really difficult focusing shots, there is the option of manual focusing.  While nice to have, I rarely use this option.  The Image Stabilization feature is a handy one in the longer shots.  \"IS\" lets one get away with a bit of camera shake without too much out-of-focus smear on the picture.  Canon does not recommend using the IS feature on tripod shots, so there is a switch to turn off the IS if desired.3.  The lens takes sharp clear pictures.  I have not been disappointed with the quality of the lens at all.Drawbacks1.  While there are not too many drawbacks to this lens, I think the major one is that the lens is bigger and heavier, in fact, much bigger and heavier than the standard 17-55 mm lenses that come with SLR cameras.  For me this is not a problem, however, for one that wants to have a lighter-weight camera, this could be considered a serious drawback.  On the other hand, a SLR camera like the Canon 20D or digital Rebel is not designed to be a smaller pocket-sized camera.  It is a larger format camera and of course the lenses will be larger (and heavier) as well.2.  Cost.  At just over 400 dollars, this lens is an investment.  Again, one has to weigh the obvious financial outlay, but the 28-135 mm lens is so superior to the cheaper 18-55 mm lens, that in my opinion, it is well worth the cost to upgrade.With this product, Canon made a great everyday camera lens.  From my perspective, the advantages far outweigh the disadvantages and I do recommend this lens to be your everyday standard camera lens.Jim \"Konedog\" Koenig   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I am not a professional or expert photographer...so take these comments with this in mind.I have two Canon cameras, a 40D and a 60D.  I have two other Canon IS USM lenses, a 17-55 f2.8 and a 70-300 f4-f5.6.  I bought this lens to fill the gap between the two.I haven't had this new lens very long, but here are my initial impressions...  First, it's shorter (when zoomed out), lighter and smaller in diameter than the 17-55 f2.8 lens that was previously our typical carry-around lens.  Obviously, it doesn't work as well in low light as the f2.8 lens, but that's to be expected.  Still, it takes very nice pictures, and doesn't seem too limited by the smaller aperture.  The colors seem accurate, and the IS seems to work very well.The barrel doesn't rotate, either when zooming or focusing, so it is possible to use filters that rely on a fixed orientation.  This is not the case with my 70-300mm zoom...that lens rotates as it focuses.  Though it isn't a big deal to me, others might be more concerned with this.My only complaint with this lens is that, unlike my other two Canon IS USM zoom lenses, it will extend under it's own weight when the camera is facing down.  And there is no lock (again, unlike my other two lenses) to keep it in it's shortest length during transport.  This annoys me when I'm carrying the camera.Comparing pictures taken with this lens to those taken with my 70-300 lens (at 70 and 135...the widest two lengths common to both lenses)...this lens seemed to have slightly more vivid colors, and a wider DOF.  The depth of field was to be expected, I'd think, given the shorter lens and slightly larger aperture.  The more vivid colors, I guess, could be explained the same way, though the difference was very small.  Both lenses produced very nice results, IMO.My lens was a white-box lens...which was not mentioned in the product description.  I half-expected this, given that the price I paid was low...lower even than the current prime price shown on Amazon for this item.  But I would like to have seen the item description accurately state this up front.  The lens came wrapped in a single layer of bubble-wrap inside a plain white cardboard box.  This was, in turn, shipped inside a slightly larger box and padded with packing paper.  There was no documentation or software included (save for the warranty card, which WAS included), as you'd get with a lens sold in retail packaging...so be aware that this is the case.  Nonetheless, my lens arrived quickly, and intact.  My order was fulfilled by ALLTIMEDEALS.   \n",
              "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    After being disappointed by a $50 pair of Sony headphones, I snagged these Audio-Technica's based on the reviews here on Amazon. I'm very impressed with the quality of these headphones. The cord is very long and durable, the jack is strong and well constructed. The headphones themselves are very comfortable, block out a ton of background noise, and aren't too bulky or heavy. They're very durable and can take a beating.The sound quality for a non-amplified pair of headphones is nothing short of amazing. The majority of headphones in this price range are boomy, obnoxious headphones with poor midrange and high end performance. The ATH-M30 is incredibly well balanced with heavy lows, comfortable mids, and stunningly clear highs. I can't recommend a better pair of headphones in this price range.   \n",
              "\n",
              "                                         answers.text  \n",
              "0  [I have been a headphone fanatic for thirty years]  \n",
              "1                                                  []  \n",
              "2                                                  []  \n",
              "3                          [I do recommend this lens]  \n",
              "4                                                  []  \n",
              "5                 [The cord is very long and durable]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cebcab3-f3c6-48b9-bd7b-00b3a07b3aef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answers.text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How would you describe the texture of the lens at all focal lengths above 150mm?</td>\n",
              "      <td>UPDATED: 5/20/2011:  I used my D700, and only my 50mm F1.8 to capture my Grandson's first haircut!  I posted an image here.  And, on the way home following the haircut, a clearing storm brought some gorgeous bluish-black clouds at dusk so I swung down towards the river and shot a couple of shots with the 50mm.  I posted one here called \"Blue Hour\".  Enjoy.  Seriously, can't go wrong -- though the price seems to be creeping upwards...This 50mm 1.8 is an excellent purchase at around a hundred bucks.  I hate to use the word investment, because we know camera equipment is definitely NOT an investment.  I bought it because I heard so much about it, and, I had a 50mm back in my old film days.  I have not  been disappointed.  I will agree with  many here who say that at F1.8 the results are less than stellar.  This is true--- there is a lack of contrast, not necessarily sharpness (at least in my copy of the lens) that you will notice.  Since I know that as a fact going in to a shoot or session, I set my aperture at F2.0, or F2.2 on my D700, or D300.  This solves the problem.  The resulting images at F 2.0 and above are amazingly sharp, and clear.  Don't get me wrong, I love my 16-35F4VR, and my 24-70F2.8 but this 50mm rocks as a standalone lens when the situation demands fast lens.  As a matter of fact, in a few hours I'm heading off to my grandsons first haircut of his life.  What did I pack?  The D700 (for better high ISO performance than the D300), and my 50mm 1.8.For the price (which seems to have risen lately and rightly so) you can't go wrong.  Even if you have other zoom lenses that cover this range as I do, this lens is unbelievably useful in low light to no light situations.  Personally, I'm lazy and hate zooming with my feet, but I'd much rather do that with this lens, than either using flash, or blurring photos of important events.The lens finish is plasticy but so what?  Are you going to be banging it around on a regular basis?  My 50mm travels with me just about everywhere either in a camera bag, or in my North Face Recon backpack (not a camera backpack) just about everywhere, and I pump about 80,000 images a year per body, between landscapes, motorsports, portraits, etc.  So far, so good.  It does stand up to a beating.  I do not use any protective filter on it as the glass is relatively well recessed on this lens.When I do need to use filters such as polarizers, or ND's, I have step-up rings that take the lens from the 52mm size to 77mm which is the standard size of all my filters. It does look \"strange\" having the tiny little 50mm lens hidden behind a huge 77mm filter, but it WORKS.Again, if you are looking to make an investment -- there's that ugly word again, make that acquisition, to your photo gear you can't go wrong at this price point; If you wind up hating it, there's always the ability to return it, or sell it on eBay.Enjoy.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How is the thing?</td>\n",
              "      <td>It worked fine at the start but within a week individual ports ceased to function (so far 2).  Although I have populated all the ports most are not in constant use (Camera, GPS, Palm PDA, SD-reader).  Seems like this should be able to handle all of this.  Amazon replaced it but I'm still worried that the new one wont be any better.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How do you like the lens?</td>\n",
              "      <td>I bought this lens for my Canon 20D digital camera and have found it to be a great all-purpose, everyday-use lens.  Here are the best features from my perspective:1.  The range of telephoto zoom is adequate for 90% of photo opportunites.  28-135 mm telephoto in digital photography translates into 48-230 mm in SLR film photography.  Since a standard camera lens is 50-55 mm, the starting range of this zoom lens equals that and then has the added versatility of zooming up to 135 mm (or 230mm in old style camera figures).  In my opinion, this added range of framing a shot gives the photographer so much more creativity, as well as being able to bring objects into closer, more intimate range.  I mentioned that this lens is good for 90% of all general camera shots; the missing 10% are those pictures that require a better zoom (more telephoto zoom), and those pics that need a wider field of view.  You may find that for group photos in close proximity, you want to take a step backwards to get everybody in the frame.  This is not a problem unless you simply don't have the room to take that step back.  I solved this problem by switching back to the original 18-55mm lens that came with the camera.  For the more distant shots that can't be drawn into the 135mm zoom of this lens I purchased a better telephoto zoom.2.  The lens has autofocus and IS stabilization technology.  For one used to manual focus lenses in SLR film photography, the addition of a fast autofocus lens is a terrific feature! I used to miss those spur of the moment shots because I was trying to achieve focus.  With this lens, you make those shots, because within a milisecond of depressing the shutter down halfway, the picture snaps into focus!  I absolutely love this feature!  The focuser has many points of potential focus, so it adapts easily to virtually all focusing situations.  For the really difficult focusing shots, there is the option of manual focusing.  While nice to have, I rarely use this option.  The Image Stabilization feature is a handy one in the longer shots.  \"IS\" lets one get away with a bit of camera shake without too much out-of-focus smear on the picture.  Canon does not recommend using the IS feature on tripod shots, so there is a switch to turn off the IS if desired.3.  The lens takes sharp clear pictures.  I have not been disappointed with the quality of the lens at all.Drawbacks1.  While there are not too many drawbacks to this lens, I think the major one is that the lens is bigger and heavier, in fact, much bigger and heavier than the standard 17-55 mm lenses that come with SLR cameras.  For me this is not a problem, however, for one that wants to have a lighter-weight camera, this could be considered a serious drawback.  On the other hand, a SLR camera like the Canon 20D or digital Rebel is not designed to be a smaller pocket-sized camera.  It is a larger format camera and of course the lenses will be larger (and heavier) as well.2.  Cost.  At just over 400 dollars, this lens is an investment.  Again, one has to weigh the obvious financial outlay, but the 28-135 mm lens is so superior to the cheaper 18-55 mm lens, that in my opinion, it is well worth the cost to upgrade.With this product, Canon made a great everyday camera lens.  From my perspective, the advantages far outweigh the disadvantages and I do recommend this lens to be your everyday standard camera lens.Jim \"Konedog\" Koenig</td>\n",
              "      <td>[I do recommend this lens]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How is the contrast?</td>\n",
              "      <td>I am not a professional or expert photographer...so take these comments with this in mind.I have two Canon cameras, a 40D and a 60D.  I have two other Canon IS USM lenses, a 17-55 f2.8 and a 70-300 f4-f5.6.  I bought this lens to fill the gap between the two.I haven't had this new lens very long, but here are my initial impressions...  First, it's shorter (when zoomed out), lighter and smaller in diameter than the 17-55 f2.8 lens that was previously our typical carry-around lens.  Obviously, it doesn't work as well in low light as the f2.8 lens, but that's to be expected.  Still, it takes very nice pictures, and doesn't seem too limited by the smaller aperture.  The colors seem accurate, and the IS seems to work very well.The barrel doesn't rotate, either when zooming or focusing, so it is possible to use filters that rely on a fixed orientation.  This is not the case with my 70-300mm zoom...that lens rotates as it focuses.  Though it isn't a big deal to me, others might be more concerned with this.My only complaint with this lens is that, unlike my other two Canon IS USM zoom lenses, it will extend under it's own weight when the camera is facing down.  And there is no lock (again, unlike my other two lenses) to keep it in it's shortest length during transport.  This annoys me when I'm carrying the camera.Comparing pictures taken with this lens to those taken with my 70-300 lens (at 70 and 135...the widest two lengths common to both lenses)...this lens seemed to have slightly more vivid colors, and a wider DOF.  The depth of field was to be expected, I'd think, given the shorter lens and slightly larger aperture.  The more vivid colors, I guess, could be explained the same way, though the difference was very small.  Both lenses produced very nice results, IMO.My lens was a white-box lens...which was not mentioned in the product description.  I half-expected this, given that the price I paid was low...lower even than the current prime price shown on Amazon for this item.  But I would like to have seen the item description accurately state this up front.  The lens came wrapped in a single layer of bubble-wrap inside a plain white cardboard box.  This was, in turn, shipped inside a slightly larger box and padded with packing paper.  There was no documentation or software included (save for the warranty card, which WAS included), as you'd get with a lens sold in retail packaging...so be aware that this is the case.  Nonetheless, my lens arrived quickly, and intact.  My order was fulfilled by ALLTIMEDEALS.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Is the cord safe to grab the transformer?</td>\n",
              "      <td>After being disappointed by a $50 pair of Sony headphones, I snagged these Audio-Technica's based on the reviews here on Amazon. I'm very impressed with the quality of these headphones. The cord is very long and durable, the jack is strong and well constructed. The headphones themselves are very comfortable, block out a ton of background noise, and aren't too bulky or heavy. They're very durable and can take a beating.The sound quality for a non-amplified pair of headphones is nothing short of amazing. The majority of headphones in this price range are boomy, obnoxious headphones with poor midrange and high end performance. The ATH-M30 is incredibly well balanced with heavy lows, comfortable mids, and stunningly clear highs. I can't recommend a better pair of headphones in this price range.</td>\n",
              "      <td>[The cord is very long and durable]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cebcab3-f3c6-48b9-bd7b-00b3a07b3aef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cebcab3-f3c6-48b9-bd7b-00b3a07b3aef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cebcab3-f3c6-48b9-bd7b-00b3a07b3aef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1f62c9cd-a3b3-47f8-97c8-c28389af284d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f62c9cd-a3b3-47f8-97c8-c28389af284d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1f62c9cd-a3b3-47f8-97c8-c28389af284d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.schema import EvaluationResult, MultiLabel, Label, Document, Answer\n",
        "\n",
        "'''\n",
        "Load the test gold-standard to the label index of the document store.\n",
        "This will be used for the evaluation.\n",
        "'''\n",
        "\n",
        "labels = []\n",
        "for i, row in dfs[\"test\"].iterrows():\n",
        "\n",
        "\t# Metadata used for filtering in the Retriever\n",
        "\tmeta = {\"item_id\": row[\"title\"], \"question_id\": row[\"id\"]}\n",
        "\n",
        "\t# Populate labels for questions with answers\n",
        "\tif len(row[\"answers.text\"]):\n",
        "\t\tfor answer in row[\"answers.text\"]:\n",
        "\t\t\tlabel = Label(\n",
        "\t\t\t\tquery=row[\"question\"],\n",
        "        answer= Answer(\n",
        "            answer = answer),\n",
        "        document = Document(\n",
        "            id = i,\n",
        "            content_type=\"text\",\n",
        "            content = row[\"context\"]\n",
        "        ),origin = \"gold-label\",\n",
        "\t\t\t\tmeta=meta,\n",
        "        is_correct_answer=True, is_correct_document=True,no_answer=False)\n",
        "\t\t\tlabels.append(label)\n",
        "\telse:\n",
        "\t\t# Populate labels for questions without answers\n",
        "\t\tlabel = Label(\n",
        "\t\tquery=row[\"question\"],\n",
        "    answer = Answer(\n",
        "      answer = \"\"),\n",
        "    document = Document(\n",
        "            id = i,\n",
        "            content_type=\"text\",\n",
        "            content = row[\"context\"]\n",
        "        ), origin=\"gold-label\",\n",
        "\t\tmeta=meta, is_correct_answer=True, is_correct_document=True,\n",
        "\t\tno_answer=True)\n",
        "\t\tlabels.append(label)"
      ],
      "metadata": {
        "id": "zLuJ_HjYNtx7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpT0QnW619Qd",
        "outputId": "5ace711d-37a9-4e4d-a970-77b208221c2a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Label: {'id': '0df16ae3-f97e-4a94-9f5d-1a4a5a01373c', 'query': 'What is the tonal balance of these headphones?', 'document': {'id': '0', 'content': \"I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.\", 'content_type': 'text', 'meta': {}, 'id_hash_keys': ['content'], 'score': None, 'embedding': None}, 'is_correct_answer': True, 'is_correct_document': True, 'origin': 'gold-label', 'answer': {'answer': 'I have been a headphone fanatic for thirty years', 'type': 'extractive', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': None, 'meta': {}}, 'pipeline_id': None, 'created_at': '2023-12-13 14:14:11', 'updated_at': None, 'meta': {'item_id': 'B00001WRSJ', 'question_id': 'd0781d13200014aa25860e44da9d5ea7'}, 'filters': None}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write the labels to the label index of the document store\n",
        "document_store.write_labels(labels, index=\"label\")\n",
        "print(f\"\"\"Loaded {document_store.get_label_count(index=\"label\")} \\\n",
        "question-answer pairs\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSN8Lj0PUJWd",
        "outputId": "e9d28805-be9d-43f1-ae31-c3b534e0e001"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 910 question-answer pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a list of MultLabel objects containing the mapping between the question ID and the corresponding answer\n",
        "labels_agg = document_store.get_all_labels_aggregated(\n",
        "  index=\"label\",\n",
        "  open_domain=True,\n",
        "  aggregate_by_meta=[\"item_id\"]\n",
        ")\n",
        "print(len(labels_agg))\n",
        "#Will aggregate the question answer pair associated with a unique-id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO1PHh89U5Bz",
        "outputId": "33f672d5-c663-4222-88d8-d25782c3ea82"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels_agg[109])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol1Mb-pQViwx",
        "outputId": "2bfaa591-7a77-46bb-e459-ce331c9aecb9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MultiLabel: {'labels': [{'id': '80eeb443-5f63-445e-a8c9-2dc62a812509', 'query': 'How does the fan work?', 'document': {'id': '112', 'content': 'the usb on the back caused my mac to restart when i would plug something into about 50% of the time.  very annoying but the fan is really really good!', 'content_type': 'text', 'meta': {}, 'id_hash_keys': ['content'], 'score': None, 'embedding': None}, 'is_correct_answer': True, 'is_correct_document': True, 'origin': 'gold-label', 'answer': {'answer': 'the fan is really really good', 'type': 'extractive', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': None, 'meta': {}}, 'pipeline_id': None, 'created_at': '2023-12-13 13:25:33', 'updated_at': '2023-12-13 13:25:33', 'meta': {'item_id': 'B002MU1ZRS', 'question_id': '5a9b7616541f700f103d21f8ad41bc4b'}, 'filters': {'item_id': ['B002MU1ZRS']}}, {'id': '63dbd481-f5c2-4e50-8793-2bb6ce5134e4', 'query': 'How does the fan work?', 'document': {'id': '113', 'content': 'In most demanding games, my GPU will consistently soar to 90-93 degrees Celsius. I didn\\'t like seeing temps in the 90s so I figured I would pick up this Cooler Master for a shade over $20. Is it worth it? I think it is.My Sager NP8130 is 15.6\" and this cooler fits it just about perfectly - I have maybe 1\" of extra room. My laptop\\'s rubber stops on the bottom keep it anchored pretty well, and the fan itself isn\\'t super loud. There is an adjustable dial to change fan speed, but when I\\'m gaming, I generally just have it on max, and when I\\'m not gaming, I turn the cooling pad off altogether.The one thing I would make sure you do is use the little legs on the bottom of the cooling pad to prop it up an extra half inch or so. It makes a world of difference in how much more air can flow through under the pad and up to your laptop. Also, beware of using this on top of a table cloth - it seems to impede air flow as well. With the legs propping up the cooling pad, my GPU temps only hit about 84-86 degrees, but without it propped up, my GPU is still 90-91 degrees.Overall, it\\'s a small ~$20 investment to potentially increase the life of my laptop as a whole.', 'content_type': 'text', 'meta': {}, 'id_hash_keys': ['content'], 'score': None, 'embedding': None}, 'is_correct_answer': True, 'is_correct_document': True, 'origin': 'gold-label', 'answer': {'answer': 'this cooler fits it just about perfectly', 'type': 'extractive', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': None, 'meta': {}}, 'pipeline_id': None, 'created_at': '2023-12-13 13:25:33', 'updated_at': '2023-12-13 13:25:33', 'meta': {'item_id': 'B002MU1ZRS', 'question_id': 'f20dae56410f31632d6a9f8f8284657a'}, 'filters': {'item_id': ['B002MU1ZRS']}}, {'id': '6419c6ac-e61b-49ff-9ea5-2951283ea1d6', 'query': 'How does the fan work?', 'document': {'id': '113', 'content': 'In most demanding games, my GPU will consistently soar to 90-93 degrees Celsius. I didn\\'t like seeing temps in the 90s so I figured I would pick up this Cooler Master for a shade over $20. Is it worth it? I think it is.My Sager NP8130 is 15.6\" and this cooler fits it just about perfectly - I have maybe 1\" of extra room. My laptop\\'s rubber stops on the bottom keep it anchored pretty well, and the fan itself isn\\'t super loud. There is an adjustable dial to change fan speed, but when I\\'m gaming, I generally just have it on max, and when I\\'m not gaming, I turn the cooling pad off altogether.The one thing I would make sure you do is use the little legs on the bottom of the cooling pad to prop it up an extra half inch or so. It makes a world of difference in how much more air can flow through under the pad and up to your laptop. Also, beware of using this on top of a table cloth - it seems to impede air flow as well. With the legs propping up the cooling pad, my GPU temps only hit about 84-86 degrees, but without it propped up, my GPU is still 90-91 degrees.Overall, it\\'s a small ~$20 investment to potentially increase the life of my laptop as a whole.', 'content_type': 'text', 'meta': {}, 'id_hash_keys': ['content'], 'score': None, 'embedding': None}, 'is_correct_answer': True, 'is_correct_document': True, 'origin': 'gold-label', 'answer': {'answer': \"the fan itself isn't super loud. There is an adjustable dial to change fan speed\", 'type': 'extractive', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': None, 'meta': {}}, 'pipeline_id': None, 'created_at': '2023-12-13 13:25:33', 'updated_at': '2023-12-13 13:25:33', 'meta': {'item_id': 'B002MU1ZRS', 'question_id': 'f20dae56410f31632d6a9f8f8284657a'}, 'filters': {'item_id': ['B002MU1ZRS']}}], 'query': 'How does the fan work?', 'filters': {'item_id': ['B002MU1ZRS']}, 'id': 'b4881c19bd99408985ff545742a3fb17', 'no_answer': False, 'answers': ['the fan is really really good', 'this cooler fits it just about perfectly', \"the fan itself isn't super loud. There is an adjustable dial to change fan speed\"], 'offsets_in_documents': [], 'offsets_in_contexts': [], 'document_ids': ['112', '113', '113'], 'contexts': ['the usb on the back caused my mac to restart when i would plug something into about 50% of the time.  very annoying but the fan is really really good!', 'In most demanding games, my GPU will consistently soar to 90-93 degrees Celsius. I didn\\'t like seeing temps in the 90s so I figured I would pick up this Cooler Master for a shade over $20. Is it worth it? I think it is.My Sager NP8130 is 15.6\" and this cooler fits it just about perfectly - I have maybe 1\" of extra room. My laptop\\'s rubber stops on the bottom keep it anchored pretty well, and the fan itself isn\\'t super loud. There is an adjustable dial to change fan speed, but when I\\'m gaming, I generally just have it on max, and when I\\'m not gaming, I turn the cooling pad off altogether.The one thing I would make sure you do is use the little legs on the bottom of the cooling pad to prop it up an extra half inch or so. It makes a world of difference in how much more air can flow through under the pad and up to your laptop. Also, beware of using this on top of a table cloth - it seems to impede air flow as well. With the legs propping up the cooling pad, my GPU temps only hit about 84-86 degrees, but without it propped up, my GPU is still 90-91 degrees.Overall, it\\'s a small ~$20 investment to potentially increase the life of my laptop as a whole.', 'In most demanding games, my GPU will consistently soar to 90-93 degrees Celsius. I didn\\'t like seeing temps in the 90s so I figured I would pick up this Cooler Master for a shade over $20. Is it worth it? I think it is.My Sager NP8130 is 15.6\" and this cooler fits it just about perfectly - I have maybe 1\" of extra room. My laptop\\'s rubber stops on the bottom keep it anchored pretty well, and the fan itself isn\\'t super loud. There is an adjustable dial to change fan speed, but when I\\'m gaming, I generally just have it on max, and when I\\'m not gaming, I turn the cooling pad off altogether.The one thing I would make sure you do is use the little legs on the bottom of the cooling pad to prop it up an extra half inch or so. It makes a world of difference in how much more air can flow through under the pad and up to your laptop. Also, beware of using this on top of a table cloth - it seems to impede air flow as well. With the legs propping up the cooling pad, my GPU temps only hit about 84-86 degrees, but without it propped up, my GPU is still 90-91 degrees.Overall, it\\'s a small ~$20 investment to potentially increase the life of my laptop as a whole.']}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install farm-haystack[metrics]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MnNE-WKWfXa",
        "outputId": "b6c270bd-d84f-4166-9ae5-a2ce69e795e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: farm-haystack[metrics] in /usr/local/lib/python3.10/dist-packages (1.22.1)\n",
            "Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (1.0.7)\n",
            "Requirement already satisfied: events in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (0.25.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (4.19.2)\n",
            "Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (9.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (3.11.0)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (3.1.0)\n",
            "Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (4.0.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (1.10.13)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (0.9.0)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (2.31.0)\n",
            "Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (0.9.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (1.3.2)\n",
            "Requirement already satisfied: sseclient-py in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (1.8.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (0.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (4.66.1)\n",
            "Requirement already satisfied: transformers==4.34.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (4.34.1)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (2.9.1)\n",
            "Requirement already satisfied: rapidfuzz<2.8.0,>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (2.7.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (1.11.4)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from farm-haystack[metrics]) (1.2.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[metrics]) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[metrics]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[metrics]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[metrics]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[metrics]) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[metrics]) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[metrics]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[metrics]) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2->farm-haystack[metrics]) (4.5.0)\n",
            "Requirement already satisfied: jarowinkler<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from rapidfuzz<2.8.0,>=2.0.15->farm-haystack[metrics]) (1.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[metrics]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[metrics]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[metrics]) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[metrics]) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[metrics]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[metrics]) (23.1.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[metrics]) (23.2.3)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[metrics]) (1.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[metrics]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[metrics]) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[metrics]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[metrics]) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[metrics]) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->farm-haystack[metrics]) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[metrics]) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[metrics]) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[metrics]) (0.13.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (2.2.1)\n",
            "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (0.18.0)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (3.1.40)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (2023.3.post1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (7.0.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (0.4.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (1.13.0)\n",
            "Requirement already satisfied: docker<7,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (6.1.3)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (2.2.5)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (1.2.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (2.0.23)\n",
            "Requirement already satisfied: pyarrow<15,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (10.0.1)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (3.5.1)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (3.7.1)\n",
            "Requirement already satisfied: gunicorn<22 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (21.2.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow->farm-haystack[metrics]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[metrics]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[metrics]) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[metrics]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[metrics]) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[metrics]) (7.0.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[metrics]) (0.5.13)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow->farm-haystack[metrics]) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[metrics]) (1.2.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[metrics]) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[metrics]) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[metrics]) (0.9.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow->farm-haystack[metrics]) (1.7.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->farm-haystack[metrics]) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->farm-haystack[metrics]) (2.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=2.1.0->mlflow->farm-haystack[metrics]) (4.0.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1->farm-haystack[metrics]) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow->farm-haystack[metrics]) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow->farm-haystack[metrics]) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[metrics]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[metrics]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[metrics]) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[metrics]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow->farm-haystack[metrics]) (3.1.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->farm-haystack[metrics]) (3.0.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->quantulum3->farm-haystack[metrics]) (0.6.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow->farm-haystack[metrics]) (5.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More details on how to correctly use eval() can be found [here](https://docs.haystack.deepset.ai/docs/evaluation)."
      ],
      "metadata": {
        "id": "AHwvVFosmPZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the quality of the QA pipeline on the labels_agg\n",
        "eval_result = querying_pipeline.eval(labels=labels_agg,\n",
        "                                     params={\"Retriever\": {\"top_k\": 3}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfoQcdvCVuYS",
        "outputId": "3175448f-7b28-4d57-81e8-115c1645fb46"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 68.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 68.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.15 Batches/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_result = eval_result[\"Retriever\"]\n",
        "reader_result = eval_result[\"Reader\"]"
      ],
      "metadata": {
        "id": "7yj1-YXgZVZq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can filter for all documents retrieved for a given query\n",
        "query = \"What is the tonal balance of these headphones?\"\n",
        "retriever_tone_balance = retriever_result[retriever_result[\"query\"] == query]\n",
        "retriever_tone_balance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ty2YuOVXZ8Kw",
        "outputId": "82b319c9-322c-4f54-bf5a-558748744d07"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        multilabel_id  \\\n",
              "0    1f380c5429a27445d5771686af8b73a3   \n",
              "1    1f380c5429a27445d5771686af8b73a3   \n",
              "2    1f380c5429a27445d5771686af8b73a3   \n",
              "359  a4b00b3f8ab0997d4164fee87cab56ec   \n",
              "360  a4b00b3f8ab0997d4164fee87cab56ec   \n",
              "361  a4b00b3f8ab0997d4164fee87cab56ec   \n",
              "\n",
              "                                              query  \\\n",
              "0    What is the tonal balance of these headphones?   \n",
              "1    What is the tonal balance of these headphones?   \n",
              "2    What is the tonal balance of these headphones?   \n",
              "359  What is the tonal balance of these headphones?   \n",
              "360  What is the tonal balance of these headphones?   \n",
              "361  What is the tonal balance of these headphones?   \n",
              "\n",
              "                            filters  \\\n",
              "0    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "1    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "2    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "359  b'{\"item_id\": [\"B003LPTAYI\"]}'   \n",
              "360  b'{\"item_id\": [\"B003LPTAYI\"]}'   \n",
              "361  b'{\"item_id\": [\"B003LPTAYI\"]}'   \n",
              "\n",
              "                                           gold_answers  \\\n",
              "0    [I have been a headphone fanatic for thirty years]   \n",
              "1    [I have been a headphone fanatic for thirty years]   \n",
              "2    [I have been a headphone fanatic for thirty years]   \n",
              "359                                                  []   \n",
              "360                                                  []   \n",
              "361                                                  []   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
              "0    I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  My sister's Bose headphones finally died and so, her being a super audiophile without enough money to buy the high-end stuff, i gave her my JVC HA-RX700 and she loves them even more than the Bose. So that left me with nothing, and therefore i decided to undertake the quest to find the best headphones for under $50 that I could. I looked at so many headphones, and i still loved my JVC's, but i decided i should probably try something new. and then i found these...I would say that I am...an untrained-audiophile of sorts and have just recently started to be pickier about my headphones. i can pick out minute differences in music and how headphones represent them if i really want to, but it doesn't exactly \"bother\" me terribly when bass is muddy or treble is harsh, etc. That being said, i loved my JVC's and was sad to see them go, but I've gotta say, i love these bad boys even more. I think it's the bass that separates them...it's punchier and more...accurate, you know? without being overly done. out of the box they had a bit too much sibilance (i think that's the right word), but they've broken in a bit and it's less harsh in that range. but the bass...wow. otherwise they're very similar in my opinion to the JVC's. The treble might be a tad better, but not much if at all. I don't know enough of the proper wording to describe much more about it, but that's my two cents. They're also very comfortable, not too tight or anything and very soft padding. I highly recommend them, i can't imagine headphones getting that much better. i've heard Beats by Dre, Bose, and the JVCs, and these are just the best of all of them to me.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Wow. Just wow. I'm a 22 yr old with a crazy obsession with sound and music. Audiophile? Maybe. These headphones are so perfect in every way. The sound is so crisp, clear and clean, the design is awesome and simple and the materials are very high quality. They are so comfortable even for my sensitive ears. The bass is just absolutely perfect, not choppy or muddy at all. Forget the Beats, forget the Souls by Ludacris, save yourself the money and get higher quality at half the price. There's no surprise that these have been so widely used for almost 30 years. The included adapter is perfect because it allows me to use these cans in my iPhone and home audio system which is also 100% Sony, I just love their audio hardware.   \n",
              "359                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I bought these to replace a pair of Sony Headphones I have had for years, and because I own a much nice pair of Sennheiser headphones.  The sound quality on these was outstanding, and far, far better than I expected in a product at this price point.  Everything was crisp, clear, and the headphones are comfortable.  What else is there to say?   \n",
              "360                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  I bought these thinking, what the heck? 20 bucks? And i was blown away with the sound quality, these headphones have incredible sound quality for an incredible price. They do not have a lot off bass, so all of you people looking for tons of bass, you won't get a ton of it here, but the bass present is rich and sounds great.   \n",
              "361                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What a pleasant surprise. I was really just looking for some cheaper noise cancelling headphones to wear at work. I use studio headphones and have in my home studio arsenal cans by Shure, Sony, and Beyerdynamic. These Sennheiser HD202's are simply amazing not just for the price point but for the comfort and function. The sound quality is absolutely stellar, even when listening to a 48khz AAC+ web radio stream. And now that I have these, I've noticed them being used in radio studios and being included in condenser microphone package deals. I also like the belt-clipping cable spool that comes with it so you can wind up the non-coiled cord neatly.Haven't used these for studio work as of yet but they do sound comparable to my $200 Beyerdynamic 770's and sound much better than my Sony MD7506 cans.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               gold_contexts  \\\n",
              "0    [I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.]   \n",
              "1    [I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.]   \n",
              "2    [I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.]   \n",
              "359                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
              "360                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
              "361                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
              "\n",
              "     gold_id_match  context_match  answer_match  gold_id_or_answer_match  ...  \\\n",
              "0              0.0            1.0           1.0                      1.0  ...   \n",
              "1              0.0            0.0           0.0                      0.0  ...   \n",
              "2              0.0            0.0           0.0                      0.0  ...   \n",
              "359            0.0            0.0           0.0                      0.0  ...   \n",
              "360            0.0            0.0           0.0                      0.0  ...   \n",
              "361            0.0            0.0           0.0                      0.0  ...   \n",
              "\n",
              "     rank                       document_id  gold_document_ids  \\\n",
              "0     1.0  a73f54ddc5b1fcc7f4fbf04bd564a278                [0]   \n",
              "1     2.0  c2c40f423a0d6628a86091ad63de8253                [0]   \n",
              "2     3.0  953ef35210176820372f802d6c3136da                [0]   \n",
              "359   1.0  8f1ed0c9606409980983dff322502f0d                 []   \n",
              "360   2.0  c6297226696fbfff2ad8d1dc884dc6f2                 []   \n",
              "361   3.0  bf6ce2f3884ba2531316d4b5f33d5d1c                 []   \n",
              "\n",
              "     gold_documents_id_match  gold_contexts_similarity  gold_answers_match  \\\n",
              "0                      [0.0]                   [100.0]               [1.0]   \n",
              "1                      [0.0]       [44.41732763880415]               [0.0]   \n",
              "2                      [0.0]       [44.70426409903714]               [0.0]   \n",
              "359                       []                        []               [0.0]   \n",
              "360                       []                        []               [0.0]   \n",
              "361                       []                        []               [0.0]   \n",
              "\n",
              "         type       node   eval_mode index  \n",
              "0    document  Retriever  integrated     0  \n",
              "1    document  Retriever  integrated     1  \n",
              "2    document  Retriever  integrated     2  \n",
              "359  document  Retriever  integrated     0  \n",
              "360  document  Retriever  integrated     1  \n",
              "361  document  Retriever  integrated     2  \n",
              "\n",
              "[6 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8479d372-bcdc-4f9b-a1de-5c57fb19a6fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>multilabel_id</th>\n",
              "      <th>query</th>\n",
              "      <th>filters</th>\n",
              "      <th>gold_answers</th>\n",
              "      <th>context</th>\n",
              "      <th>gold_contexts</th>\n",
              "      <th>gold_id_match</th>\n",
              "      <th>context_match</th>\n",
              "      <th>answer_match</th>\n",
              "      <th>gold_id_or_answer_match</th>\n",
              "      <th>...</th>\n",
              "      <th>rank</th>\n",
              "      <th>document_id</th>\n",
              "      <th>gold_document_ids</th>\n",
              "      <th>gold_documents_id_match</th>\n",
              "      <th>gold_contexts_similarity</th>\n",
              "      <th>gold_answers_match</th>\n",
              "      <th>type</th>\n",
              "      <th>node</th>\n",
              "      <th>eval_mode</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td>I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>a73f54ddc5b1fcc7f4fbf04bd564a278</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[100.0]</td>\n",
              "      <td>[1.0]</td>\n",
              "      <td>document</td>\n",
              "      <td>Retriever</td>\n",
              "      <td>integrated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td>My sister's Bose headphones finally died and so, her being a super audiophile without enough money to buy the high-end stuff, i gave her my JVC HA-RX700 and she loves them even more than the Bose. So that left me with nothing, and therefore i decided to undertake the quest to find the best headphones for under $50 that I could. I looked at so many headphones, and i still loved my JVC's, but i decided i should probably try something new. and then i found these...I would say that I am...an untrained-audiophile of sorts and have just recently started to be pickier about my headphones. i can pick out minute differences in music and how headphones represent them if i really want to, but it doesn't exactly \"bother\" me terribly when bass is muddy or treble is harsh, etc. That being said, i loved my JVC's and was sad to see them go, but I've gotta say, i love these bad boys even more. I think it's the bass that separates them...it's punchier and more...accurate, you know? without being overly done. out of the box they had a bit too much sibilance (i think that's the right word), but they've broken in a bit and it's less harsh in that range. but the bass...wow. otherwise they're very similar in my opinion to the JVC's. The treble might be a tad better, but not much if at all. I don't know enough of the proper wording to describe much more about it, but that's my two cents. They're also very comfortable, not too tight or anything and very soft padding. I highly recommend them, i can't imagine headphones getting that much better. i've heard Beats by Dre, Bose, and the JVCs, and these are just the best of all of them to me.</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>c2c40f423a0d6628a86091ad63de8253</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[44.41732763880415]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>document</td>\n",
              "      <td>Retriever</td>\n",
              "      <td>integrated</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td>Wow. Just wow. I'm a 22 yr old with a crazy obsession with sound and music. Audiophile? Maybe. These headphones are so perfect in every way. The sound is so crisp, clear and clean, the design is awesome and simple and the materials are very high quality. They are so comfortable even for my sensitive ears. The bass is just absolutely perfect, not choppy or muddy at all. Forget the Beats, forget the Souls by Ludacris, save yourself the money and get higher quality at half the price. There's no surprise that these have been so widely used for almost 30 years. The included adapter is perfect because it allows me to use these cans in my iPhone and home audio system which is also 100% Sony, I just love their audio hardware.</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years and have owned and used a variety of headphones over those years, to include Stax SR-5, Sennheiser HD-424 and HD-580.  The Sony MDRV6 excells as the best value of any headphone that I've ever owned.  They are especially good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable to other headphones that cost considerably more.The MDRV6 is especially well-suited for travel due to the collapsible design, and for noisy environments or for quiet environments such as a library where the sound emitted by open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously by replacing the pads with the velour pads from BeyerDynamic.  The pads that come on the MDRV6 have a non-breathable cover, and significant additional discomfort is caused by the way that the thin foam cover is glued to the pad around the inner circumference of the pad, which prevents the top and back of your ear from slipping into the space between the pad and the face of the headphone.  This forces the pad to rest on the back of the ear, which compresses the ear and eventually becomes uncomfortable.  I read on a web forum where several people had replaced the pads (which eventually come apart) with a velour pad made by BeyerDynamic, and after I did this replacement on my one pair that had a damaged pad, the increase in comfort was so great that I immediately did the other pair.  The thin cover can be glued down to the headphone face if needed to hold it in place, which then allows the top and rear of your ear to naturally  slide under the inner circumference of the pad, which is considerably more comfortable.  I can recommend this trivial modification without reservation to anyone who owns these headphones.  Even if you don't replace the pads with the BeyerDynamic velour pads, I suggest removing the pads anyway, then carefully separating the thin cover from the pad, and glueing the cover directly to the headphone surface.]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>953ef35210176820372f802d6c3136da</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[44.70426409903714]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>document</td>\n",
              "      <td>Retriever</td>\n",
              "      <td>integrated</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>a4b00b3f8ab0997d4164fee87cab56ec</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B003LPTAYI\"]}'</td>\n",
              "      <td>[]</td>\n",
              "      <td>I bought these to replace a pair of Sony Headphones I have had for years, and because I own a much nice pair of Sennheiser headphones.  The sound quality on these was outstanding, and far, far better than I expected in a product at this price point.  Everything was crisp, clear, and the headphones are comfortable.  What else is there to say?</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8f1ed0c9606409980983dff322502f0d</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>document</td>\n",
              "      <td>Retriever</td>\n",
              "      <td>integrated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>a4b00b3f8ab0997d4164fee87cab56ec</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B003LPTAYI\"]}'</td>\n",
              "      <td>[]</td>\n",
              "      <td>I bought these thinking, what the heck? 20 bucks? And i was blown away with the sound quality, these headphones have incredible sound quality for an incredible price. They do not have a lot off bass, so all of you people looking for tons of bass, you won't get a ton of it here, but the bass present is rich and sounds great.</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>c6297226696fbfff2ad8d1dc884dc6f2</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>document</td>\n",
              "      <td>Retriever</td>\n",
              "      <td>integrated</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>a4b00b3f8ab0997d4164fee87cab56ec</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B003LPTAYI\"]}'</td>\n",
              "      <td>[]</td>\n",
              "      <td>What a pleasant surprise. I was really just looking for some cheaper noise cancelling headphones to wear at work. I use studio headphones and have in my home studio arsenal cans by Shure, Sony, and Beyerdynamic. These Sennheiser HD202's are simply amazing not just for the price point but for the comfort and function. The sound quality is absolutely stellar, even when listening to a 48khz AAC+ web radio stream. And now that I have these, I've noticed them being used in radio studios and being included in condenser microphone package deals. I also like the belt-clipping cable spool that comes with it so you can wind up the non-coiled cord neatly.Haven't used these for studio work as of yet but they do sound comparable to my $200 Beyerdynamic 770's and sound much better than my Sony MD7506 cans.</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>bf6ce2f3884ba2531316d4b5f33d5d1c</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>document</td>\n",
              "      <td>Retriever</td>\n",
              "      <td>integrated</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8479d372-bcdc-4f9b-a1de-5c57fb19a6fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8479d372-bcdc-4f9b-a1de-5c57fb19a6fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8479d372-bcdc-4f9b-a1de-5c57fb19a6fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df4518ca-18f8-44fc-8826-b00be1ee5706\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df4518ca-18f8-44fc-8826-b00be1ee5706')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df4518ca-18f8-44fc-8826-b00be1ee5706 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader_tone_balance = reader_result[reader_result[\"query\"] == query]\n",
        "reader_tone_balance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jz7QG6rjaNjD",
        "outputId": "b3074975-75cf-4337-8748-e0b50687fa5a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        multilabel_id  \\\n",
              "0    1f380c5429a27445d5771686af8b73a3   \n",
              "1    1f380c5429a27445d5771686af8b73a3   \n",
              "2    1f380c5429a27445d5771686af8b73a3   \n",
              "3    1f380c5429a27445d5771686af8b73a3   \n",
              "4    1f380c5429a27445d5771686af8b73a3   \n",
              "664  a4b00b3f8ab0997d4164fee87cab56ec   \n",
              "665  a4b00b3f8ab0997d4164fee87cab56ec   \n",
              "666  a4b00b3f8ab0997d4164fee87cab56ec   \n",
              "667  a4b00b3f8ab0997d4164fee87cab56ec   \n",
              "\n",
              "                                              query  \\\n",
              "0    What is the tonal balance of these headphones?   \n",
              "1    What is the tonal balance of these headphones?   \n",
              "2    What is the tonal balance of these headphones?   \n",
              "3    What is the tonal balance of these headphones?   \n",
              "4    What is the tonal balance of these headphones?   \n",
              "664  What is the tonal balance of these headphones?   \n",
              "665  What is the tonal balance of these headphones?   \n",
              "666  What is the tonal balance of these headphones?   \n",
              "667  What is the tonal balance of these headphones?   \n",
              "\n",
              "                            filters  \\\n",
              "0    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "1    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "2    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "3    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "4    b'{\"item_id\": [\"B00001WRSJ\"]}'   \n",
              "664  b'{\"item_id\": [\"B003LPTAYI\"]}'   \n",
              "665  b'{\"item_id\": [\"B003LPTAYI\"]}'   \n",
              "666  b'{\"item_id\": [\"B003LPTAYI\"]}'   \n",
              "667  b'{\"item_id\": [\"B003LPTAYI\"]}'   \n",
              "\n",
              "                                           gold_answers  \\\n",
              "0    [I have been a headphone fanatic for thirty years]   \n",
              "1    [I have been a headphone fanatic for thirty years]   \n",
              "2    [I have been a headphone fanatic for thirty years]   \n",
              "3    [I have been a headphone fanatic for thirty years]   \n",
              "4    [I have been a headphone fanatic for thirty years]   \n",
              "664                                                  []   \n",
              "665                                                  []   \n",
              "666                                                  []   \n",
              "667                                                  []   \n",
              "\n",
              "                                                              answer  \\\n",
              "0                                                   octave-to-octave   \n",
              "1                                                                      \n",
              "2                                  it's punchier and more...accurate   \n",
              "3                                               perfect in every way   \n",
              "4                                                        comfortable   \n",
              "664                                                                    \n",
              "665  Everything was crisp, clear, and the headphones are comfortable   \n",
              "666                                             comfort and function   \n",
              "667                                  They do not have a lot off bass   \n",
              "\n",
              "                                                                                                                                                    context  \\\n",
              "0    ally good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable    \n",
              "1                                                                                                                                                      None   \n",
              "2    oys even more. I think it's the bass that separates them...it's punchier and more...accurate, you know? without being overly done. out of the box they   \n",
              "3    with sound and music. Audiophile? Maybe. These headphones are so perfect in every way. The sound is so crisp, clear and clean, the design is awesome a   \n",
              "4     open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously   \n",
              "664                                                                                                                                                    None   \n",
              "665  better than I expected in a product at this price point.  Everything was crisp, clear, and the headphones are comfortable.  What else is there to say?   \n",
              "666  02's are simply amazing not just for the price point but for the comfort and function. The sound quality is absolutely stellar, even when listening to   \n",
              "667  ones have incredible sound quality for an incredible price. They do not have a lot off bass, so all of you people looking for tons of bass, you won't    \n",
              "\n",
              "     exact_match   f1  exact_match_context_scope  f1_context_scope  ...  \\\n",
              "0            0.0  0.0                        0.0               0.0  ...   \n",
              "1            0.0  0.0                        0.0               0.0  ...   \n",
              "2            0.0  0.0                        0.0               0.0  ...   \n",
              "3            0.0  0.0                        0.0               0.0  ...   \n",
              "4            0.0  0.0                        0.0               0.0  ...   \n",
              "664          1.0  1.0                        1.0               1.0  ...   \n",
              "665          0.0  0.0                        0.0               0.0  ...   \n",
              "666          0.0  0.0                        0.0               0.0  ...   \n",
              "667          0.0  0.0                        0.0               0.0  ...   \n",
              "\n",
              "              offsets_in_context  gold_offsets_in_contexts  \\\n",
              "0     [{'start': 67, 'end': 83}]                        []   \n",
              "1       [{'start': 0, 'end': 0}]                        []   \n",
              "2     [{'start': 59, 'end': 92}]                        []   \n",
              "3     [{'start': 65, 'end': 85}]                        []   \n",
              "4     [{'start': 70, 'end': 81}]                        []   \n",
              "664     [{'start': 0, 'end': 0}]                        []   \n",
              "665  [{'start': 58, 'end': 121}]                        []   \n",
              "666   [{'start': 65, 'end': 85}]                        []   \n",
              "667   [{'start': 60, 'end': 91}]                        []   \n",
              "\n",
              "     gold_answers_exact_match  gold_answers_f1 gold_documents_id_match  \\\n",
              "0                         [0]              [0]                   [0.0]   \n",
              "1                         [0]              [0]                   [0.0]   \n",
              "2                         [0]              [0]                   [0.0]   \n",
              "3                         [0]              [0]                   [0.0]   \n",
              "4                         [0]              [0]                   [0.0]   \n",
              "664                       [1]              [1]                      []   \n",
              "665                       [0]              [0]                      []   \n",
              "666                       [0]              [0]                      []   \n",
              "667                       [0]              [0]                      []   \n",
              "\n",
              "     gold_contexts_similarity    type    node   eval_mode index  \n",
              "0                     [100.0]  answer  Reader  integrated     0  \n",
              "1                       [0.0]  answer  Reader  integrated     1  \n",
              "2                      [47.0]  answer  Reader  integrated     2  \n",
              "3                      [50.0]  answer  Reader  integrated     3  \n",
              "4                     [100.0]  answer  Reader  integrated     4  \n",
              "664                        []  answer  Reader  integrated     0  \n",
              "665                        []  answer  Reader  integrated     1  \n",
              "666                        []  answer  Reader  integrated     2  \n",
              "667                        []  answer  Reader  integrated     3  \n",
              "\n",
              "[9 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1df210d-d701-46eb-9488-8c89321fb026\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>multilabel_id</th>\n",
              "      <th>query</th>\n",
              "      <th>filters</th>\n",
              "      <th>gold_answers</th>\n",
              "      <th>answer</th>\n",
              "      <th>context</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>f1</th>\n",
              "      <th>exact_match_context_scope</th>\n",
              "      <th>f1_context_scope</th>\n",
              "      <th>...</th>\n",
              "      <th>offsets_in_context</th>\n",
              "      <th>gold_offsets_in_contexts</th>\n",
              "      <th>gold_answers_exact_match</th>\n",
              "      <th>gold_answers_f1</th>\n",
              "      <th>gold_documents_id_match</th>\n",
              "      <th>gold_contexts_similarity</th>\n",
              "      <th>type</th>\n",
              "      <th>node</th>\n",
              "      <th>eval_mode</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td>octave-to-octave</td>\n",
              "      <td>ally good at producing natural-sounding deep bass, and the overall octave-to-octave balance is excellent.  The sound quality is all in all comparable</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 67, 'end': 83}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[100.0]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 0, 'end': 0}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td>it's punchier and more...accurate</td>\n",
              "      <td>oys even more. I think it's the bass that separates them...it's punchier and more...accurate, you know? without being overly done. out of the box they</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 59, 'end': 92}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[47.0]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td>perfect in every way</td>\n",
              "      <td>with sound and music. Audiophile? Maybe. These headphones are so perfect in every way. The sound is so crisp, clear and clean, the design is awesome a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 65, 'end': 85}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[50.0]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1f380c5429a27445d5771686af8b73a3</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B00001WRSJ\"]}'</td>\n",
              "      <td>[I have been a headphone fanatic for thirty years]</td>\n",
              "      <td>comfortable</td>\n",
              "      <td>open-back headphones would distract others.The MDRV6 is not quite as comfortable as some other headphones, but the comfort can be improved enormously</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 70, 'end': 81}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0.0]</td>\n",
              "      <td>[100.0]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>a4b00b3f8ab0997d4164fee87cab56ec</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B003LPTAYI\"]}'</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 0, 'end': 0}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>a4b00b3f8ab0997d4164fee87cab56ec</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B003LPTAYI\"]}'</td>\n",
              "      <td>[]</td>\n",
              "      <td>Everything was crisp, clear, and the headphones are comfortable</td>\n",
              "      <td>better than I expected in a product at this price point.  Everything was crisp, clear, and the headphones are comfortable.  What else is there to say?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 58, 'end': 121}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>a4b00b3f8ab0997d4164fee87cab56ec</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B003LPTAYI\"]}'</td>\n",
              "      <td>[]</td>\n",
              "      <td>comfort and function</td>\n",
              "      <td>02's are simply amazing not just for the price point but for the comfort and function. The sound quality is absolutely stellar, even when listening to</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 65, 'end': 85}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>a4b00b3f8ab0997d4164fee87cab56ec</td>\n",
              "      <td>What is the tonal balance of these headphones?</td>\n",
              "      <td>b'{\"item_id\": [\"B003LPTAYI\"]}'</td>\n",
              "      <td>[]</td>\n",
              "      <td>They do not have a lot off bass</td>\n",
              "      <td>ones have incredible sound quality for an incredible price. They do not have a lot off bass, so all of you people looking for tons of bass, you won't</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'start': 60, 'end': 91}]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>answer</td>\n",
              "      <td>Reader</td>\n",
              "      <td>integrated</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1df210d-d701-46eb-9488-8c89321fb026')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1df210d-d701-46eb-9488-8c89321fb026 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1df210d-d701-46eb-9488-8c89321fb026');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87a9db96-af30-4941-8ffb-182384cfc445\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87a9db96-af30-4941-8ffb-182384cfc445')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87a9db96-af30-4941-8ffb-182384cfc445 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the evaluation result so that we can reload it later and calculate evaluation metrics without running the pipeline again.\n",
        "eval_result.save(\"../\")"
      ],
      "metadata": {
        "id": "yT26ZfpXabf6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_eval_result = EvaluationResult.load(\"../\")\n",
        "metrics = saved_eval_result.calculate_metrics()\n",
        "print(f'Retriever - Recall (single relevant document): {metrics[\"Retriever\"][\"recall_single_hit\"]}')\n",
        "print(f'Retriever - Recall (multiple relevant documents): {metrics[\"Retriever\"][\"recall_multi_hit\"]}')\n",
        "print(f'Retriever - Mean Reciprocal Rank: {metrics[\"Retriever\"][\"mrr\"]}')\n",
        "print(f'Retriever - Precision: {metrics[\"Retriever\"][\"precision\"]}')\n",
        "print(f'Retriever - Mean Average Precision: {metrics[\"Retriever\"][\"map\"]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC2mE0JuYUQe",
        "outputId": "ece7fd1c-c2dd-4986-82e1-295ba02e0700"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever - Recall (single relevant document): 0.896969696969697\n",
            "Retriever - Recall (multiple relevant documents): 0.8911616161616162\n",
            "Retriever - Mean Reciprocal Rank: 0.8368686868686868\n",
            "Retriever - Precision: 0.7439393939393939\n",
            "Retriever - Mean Average Precision: 0.8328282828282828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Can be done like this as well\n",
        "metrics = eval_result.calculate_metrics()\n",
        "print(f'Retriever - Recall (single relevant document): {metrics[\"Retriever\"][\"recall_single_hit\"]}')\n",
        "print(f'Retriever - Recall (multiple relevant documents): {metrics[\"Retriever\"][\"recall_multi_hit\"]}')\n",
        "print(f'Retriever - Mean Reciprocal Rank: {metrics[\"Retriever\"][\"mrr\"]}')\n",
        "print(f'Retriever - Precision: {metrics[\"Retriever\"][\"precision\"]}')\n",
        "print(f'Retriever - Mean Average Precision: {metrics[\"Retriever\"][\"map\"]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi_q0nQP3nGe",
        "outputId": "a423cf6d-be22-42a4-82ed-ae74b7b4d201"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever - Recall (single relevant document): 0.896969696969697\n",
            "Retriever - Recall (multiple relevant documents): 0.8911616161616162\n",
            "Retriever - Mean Reciprocal Rank: 0.8368686868686868\n",
            "Retriever - Precision: 0.7439393939393939\n",
            "Retriever - Mean Average Precision: 0.8328282828282828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics[\"Retriever\"][\"recall_single_hit\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsAt5QcU-WL6",
        "outputId": "bff56961-5642-4eb6-8f89-63d734fb79b3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.896969696969697"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsure whether the metdata filter is being applied."
      ],
      "metadata": {
        "id": "LhIjgMSD64dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation 2\n",
        "\n",
        "While the above method is from the haystack documentation, we will now implement the way it has been mentioned in the book.\n",
        "\n",
        "In the book, a [pipeline](https://docs.haystack.deepset.ai/docs/nodes_overview) is created with the Retriever as the start node which receieves the query as input. This node is connected to an evaluation node. This whole process is encapsulated in a class called EvalRetrieverPipeline. We create an instance of this class and call the *run()* function. We pass the query, label and the filter to evaluate the retriever.\n",
        "\n",
        "First we create the EvalRetrieverPipeline class:"
      ],
      "metadata": {
        "id": "TwR4Qp5ooecC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.eval import EvalDocuments\n",
        "\n",
        "class EvalRetrieverPipeline:\n",
        "\tdef __init__(self, retriever):\n",
        "\t\t#Create the retriever\n",
        "\t\tself.retriever = retriever\n",
        "\n",
        "\t\t#Create the evaluation component\n",
        "\t\tself.eval_retriever = EvalDocuments()\n",
        "\n",
        "\t\t#Create the pipline with the retriever and the evaluator\n",
        "\t\tpipe = Pipeline()\n",
        "\n",
        "\t\t#Adding the retriever node to the pipeline. Query is the input\n",
        "\t\tpipe.add_node(component=self.retriever, name=\"ESRetriever\",\n",
        "\t\t\tinputs=[\"Query\"])\n",
        "\n",
        "\t\t#Adding the evaluator node to the pipeline. The retriever is the input.\n",
        "\t\tpipe.add_node(component=self.eval_retriever, name=\"EvalRetriever\",\n",
        "\t\t\tinputs=[\"ESRetriever\"])\n",
        "\n",
        "\t\t#Creating teh pipeline object\n",
        "\t\tself.pipeline = pipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "7BRPOyPSz7Ct",
        "outputId": "0d925560-a3fb-4324-fc4b-6a26a9adffbb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e30abae61dc3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvalDocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEvalRetrieverPipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'haystack.eval'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation 2 doesn't seem to work as there is no module called haystack.eval. The latest code from haystack(Implementation 1) seems to be the only option."
      ],
      "metadata": {
        "id": "Jvkahhh021EF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the best k in retriever"
      ],
      "metadata": {
        "id": "EK8CMBQ-4EiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topk_results = {}\n",
        "topk_values = [1,3,5,10,20]\n",
        "#topk_values = [1,3]\n",
        "for topk in topk_values:\n",
        "\teval_result = querying_pipeline.eval(labels=labels_agg,\n",
        "                                      params={\"Retriever\": {\"top_k\": topk}})\n",
        "\tmetrics = eval_result.calculate_metrics()\n",
        "\ttopk_results[topk] = {\"recall\": metrics[\"Retriever\"][\"recall_single_hit\"]}\n",
        "topk_results_df = pd.DataFrame.from_dict(topk_results, orient=\"index\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEdxbuez0lm_",
        "outputId": "2d18c2a3-24e5-42b3-bcc4-d9464f2284c4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 69.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.29 Batches/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_results_df.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "CtP44Yds4_cM",
        "outputId": "2c54ef16-f2cc-484d-89d5-bea6a61e1352"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "k5JUMs7ypsIa",
        "outputId": "4a8b629b-b1ff-4a39-d343-f9a899764fba"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      recall\n",
              "1   0.790909\n",
              "3   0.896970\n",
              "5   0.924242\n",
              "10  0.960606\n",
              "20  0.987879"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a16cd34e-f8e7-44d0-8853-7eda54ac082d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.790909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.896970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.924242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.960606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.987879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a16cd34e-f8e7-44d0-8853-7eda54ac082d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a16cd34e-f8e7-44d0-8853-7eda54ac082d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a16cd34e-f8e7-44d0-8853-7eda54ac082d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14e1fddd-f75c-4794-a775-92ab825e63a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14e1fddd-f75c-4794-a775-92ab825e63a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14e1fddd-f75c-4794-a775-92ab825e63a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dense Passage Retrieval(DPR)\n",
        "\n",
        "The main drawback of sparse retrievers are that they fail to retrieve those relevant documents which doesn't contain the terms in the query. The solution for this is to use a Dense Passage Retriever.\n",
        "\n",
        "The main idea is to use 2 encoders:\n",
        "1. to encode the question\n",
        "2. to encode the passage\n",
        "\n",
        "These encoders map the input text to d-dimensional vector representation of [CLS] token.\n",
        "\n",
        "For this we have to choose encoders which are trained for this specific purpose. The encoders will be given a question and 2 passages: relevant(positive) passage and another irrelevant(negative) passage. This encoder is trained to learn the question and the corresponding relevant passages having the highest simialrity.\n",
        "\n",
        "More details on what model to choose as the query retriever or passage retriever can be found [here](https://docs.haystack.deepset.ai/docs/retriever#dense-passage-retrieval).\n",
        "\n",
        "There are 2 steps in using a DPR retriever:\n",
        "1. Convert the questions and passages in the document store to vector embeddings.\n",
        "2. Create a pipline using the DPR retriever to get the answer.\n",
        "\n",
        "Let's start by converting the document store into vector embeddings."
      ],
      "metadata": {
        "id": "ZBWfrzdNBVKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import DensePassageRetriever\n",
        "\n",
        "#Initialize a dpr for the document store we had created\n",
        "dpr_retriever = DensePassageRetriever(document_store=document_store,\n",
        "  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
        "  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
        "embed_title=False)"
      ],
      "metadata": {
        "id": "9hFCjj4I9_HX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "d8415b74ae444c088859b710f4c33b93",
            "42ab336ea07942cea3262a79b763dc16",
            "6bb89cca1cf84a089d3c34a9991f2525",
            "df928022468a4d6b8b34226381c47cbf",
            "ea748a9849644a45a11730f3224a29d7",
            "b49162f9c48c4619ab291888f211f920",
            "f8225eafa99843d88cd043feb8433f56",
            "fd2631c7c4f74664b212dbc9046048a8",
            "447579c2ed8d40f59246dff141aaa352",
            "9efc55ad93de4fa8aa0cf1727a488f92",
            "ab129e5cec5d41fab7b990625fdc04a1",
            "09c770df98ee4571be62a88ce057b53d",
            "8bb84a965c3547ed9e8aa15392955eb9",
            "ebfc2b6cc2b6472baf9c07226324061b",
            "c6fbdb33cfdd4697ae35bd91719d3c1f",
            "0471622ca1bf4fb38d62e53acb3d4f6c",
            "fff6ae509af44561aec3d4171341864e",
            "b078f47fc26d4b188b0281af97eba1ac",
            "a59006a41b744768990488d24176ba37",
            "0bc161fec7134d749058dd2727ff125c",
            "cd0993e606d74f22a862ac7ae352c7bb",
            "50db288ee37a41eea8088f3ee85b0e9b",
            "062cfcec2539480aab0c7d7ad428d505",
            "451f6ddd5aa74d2f9e5d6f09fcfbf8d1",
            "0baa1b085f214dd38c94f1d33525adaa",
            "f0b2407aaae647a386e059451f88daab",
            "e446039e58d0407c9df8f9207938fe2f",
            "38d32a54148b4ae68aee0ffa500213d9",
            "fe56d408a27741a99b743757e3b956e7",
            "5351b55dcb5b4b0abd69ecbbd038ba79",
            "562ca17908ee4af2874f5143a33a9da0",
            "e7f69835c2184d0088bfa26b8134b9ce",
            "2df5dc79cbb44c61ab0953ac08ea398c",
            "ea9896ee9fc84073b699fd820bef4f55",
            "19c935774bb44379aaa6da596af3a1ed",
            "407336f3d7074ee8ae18fc5fbc342998",
            "1a6672156fc1428aa1537db60f34fa75",
            "60edfc0dbce04f92a5f87adee5685117",
            "1a922421d75a4df0893cf102f01666ff",
            "4e64f4a970d8473a85c9ef6d45eb6bf4",
            "7df1a70c9c3741e9a4ce7c2e7b046278",
            "7cb29a3f85eb4f04a34425217af1d854",
            "21b47dec898a499c99c7b0ac79b5e035",
            "38b90803b2554a86a7d2ddc5d416e757",
            "b284689026da43b1b6f1be6eeb991259",
            "0a49a496335b49788a4690d7b512fa0b",
            "c784febbb7e248dfbc013cf1ffed92fd",
            "973464c9358f4a869ae9c022b2af0d84",
            "efae5832bac84d488811ebe144a8af55",
            "0903341dd13d47e8ba96326ac84314da",
            "53a1f77bdac54368afa154142d8089bc",
            "188f4d451f274040b2fbcd62fd542ee9",
            "8109354217254a0fadb6464cb03435b0",
            "0055bfcc81ad473c9bd6f0f77f3473ac",
            "a3a2879572a04a0db8da3d725f5b4977",
            "be03d56f67ab4fb4b14fae4ea8553edb",
            "da4f6de24d294b60b7b89908306d586d",
            "1eeb3f38e32247869442f2638b75c208",
            "3fbb172b83db40279bf4e74e9c997731",
            "7a952f046e4d4875a33fa2b01710e550",
            "11cd43461df04732a9da02a3094144a0",
            "999bcbee10784e5780dd61b29416b14f",
            "444fd01416d043ec90938f065ad7eb03",
            "cffbdd2895e6499dbd523758bd7f3c58",
            "246c42115f1e431784da632040d05cce",
            "fa0e0ca307e847afac9cc57be45c5c96",
            "c2e1dcfd4c744909b286c0876466951e",
            "652ea54932c34897a9a4c2e0d6450f80",
            "acbfe4c2162340fe8a133f08cea736a9",
            "4a82a2103dd044eb8ac2202e99909f16",
            "1752ce80bc204fceabfa2dedd9d83dbf",
            "1094022a864849e3a41584fbcfe24366",
            "a3feb58f35b14340bcede3d8468fec70",
            "518818d243a541e8ba23f56acda83ab7",
            "e4fae264f3a84e0abbc72d0488f0fb8d",
            "561db3d1b90347d6a5492e2c5dc3b39c",
            "b8c9dc106023427a892217ab76a835e6",
            "63b3a88d857048c19966499f614ba7d9",
            "34a0788a00b64dae8741579dd95dcc2d",
            "a938a883aaae459aaba727e3c28e9480",
            "523bd6f64e744f269658f6d9d8b706dc",
            "47c6364b0fb14166bf1e97c1feaf2d0b",
            "b8918afa7aa94906a81f1c8470674375",
            "a0817d00016b4cab8dcc21e3e9053261",
            "29f76d2ca4724f2f9cd1765329fe123e",
            "883e5b48bcb04549b63ec640d85e6c55",
            "eb82ebdb3e9d44f8bd261be9039be2b1",
            "687b02a7da8a469fa384305620c99959",
            "845c5b13561e448f99501c6bfc73cb4e",
            "f39d72d095f34805af501c1416698461",
            "6090ecff667746dea0fe3e7a1d7be0fb",
            "bcc23a3aca644b3ba3a3e4539df738b1",
            "0f99103ffeff47afb745a70a83dd8e9d",
            "e5b1d2dcf9d5481ca43fb64155a3dae9",
            "c6113d737ca84db990ffd2816590e7ee",
            "3b3833101859449ea7c9f905cb161ef0",
            "39c9419f24e14e1eb83c8c447754e86a",
            "55457bcc54b1481f86538dd991f7517c",
            "42878780caec48cba598b6bca3817ff6",
            "ec58bc8306c346d7b9840708b35365e5",
            "2569729b21af43feb3ff75408e5cf53c",
            "bb6f85111351467d9ac87d67161775ac",
            "a8a1f4b7ff9f456baf02eeb0985bcc9f",
            "38ae7fa119c546e2843533ebacc138eb",
            "82682cafa3eb41f59a1841b6126a8691",
            "140971a99e4346eb9d3570b571765b76",
            "3541cc05b952463e9fd915ede6123687",
            "13577ea053544119800b7779d2b6394e",
            "05a994dad0bb40a8a931721241f5675c",
            "c34f8de64c78447aa293a531f16ff7fe"
          ]
        },
        "outputId": "a85e5a29-47be-408f-85ac-7d56aa7ac335"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8415b74ae444c088859b710f4c33b93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/493 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09c770df98ee4571be62a88ce057b53d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "062cfcec2539480aab0c7d7ad428d505"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea9896ee9fc84073b699fd820bef4f55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b284689026da43b1b6f1be6eeb991259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be03d56f67ab4fb4b14fae4ea8553edb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/492 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2e1dcfd4c744909b286c0876466951e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63b3a88d857048c19966499f614ba7d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "845c5b13561e448f99501c6bfc73cb4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec58bc8306c346d7b9840708b35365e5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply the embeddings on all the documents in our document store\n",
        "document_store.update_embeddings(retriever=dpr_retriever)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsGeGvtvlsda",
        "outputId": "2bc2585f-f225-4828-e404-530a65e2485a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating embeddings:   0%|          | 0/1615 [00:00<?, ? Docs/s]\n",
            "Create embeddings:   0%|          | 0/1616 [00:00<?, ? Docs/s]\u001b[A\n",
            "Create embeddings:   1%|          | 16/1616 [00:00<00:28, 55.89 Docs/s]\u001b[A\n",
            "Create embeddings:   2%|▏         | 32/1616 [00:00<00:23, 66.13 Docs/s]\u001b[A\n",
            "Create embeddings:   3%|▎         | 48/1616 [00:00<00:22, 70.14 Docs/s]\u001b[A\n",
            "Create embeddings:   4%|▍         | 64/1616 [00:00<00:21, 72.47 Docs/s]\u001b[A\n",
            "Create embeddings:   5%|▍         | 80/1616 [00:01<00:21, 73.12 Docs/s]\u001b[A\n",
            "Create embeddings:   6%|▌         | 96/1616 [00:01<00:20, 73.10 Docs/s]\u001b[A\n",
            "Create embeddings:   7%|▋         | 112/1616 [00:01<00:20, 74.06 Docs/s]\u001b[A\n",
            "Create embeddings:   8%|▊         | 128/1616 [00:01<00:20, 74.31 Docs/s]\u001b[A\n",
            "Create embeddings:   9%|▉         | 144/1616 [00:01<00:19, 74.67 Docs/s]\u001b[A\n",
            "Create embeddings:  10%|▉         | 160/1616 [00:02<00:19, 74.10 Docs/s]\u001b[A\n",
            "Create embeddings:  11%|█         | 176/1616 [00:02<00:19, 74.13 Docs/s]\u001b[A\n",
            "Create embeddings:  12%|█▏        | 192/1616 [00:02<00:19, 74.45 Docs/s]\u001b[A\n",
            "Create embeddings:  13%|█▎        | 208/1616 [00:02<00:18, 74.82 Docs/s]\u001b[A\n",
            "Create embeddings:  14%|█▍        | 224/1616 [00:03<00:18, 74.62 Docs/s]\u001b[A\n",
            "Create embeddings:  15%|█▍        | 240/1616 [00:03<00:18, 74.00 Docs/s]\u001b[A\n",
            "Create embeddings:  16%|█▌        | 256/1616 [00:03<00:18, 73.99 Docs/s]\u001b[A\n",
            "Create embeddings:  17%|█▋        | 272/1616 [00:03<00:18, 74.15 Docs/s]\u001b[A\n",
            "Create embeddings:  18%|█▊        | 288/1616 [00:03<00:17, 74.49 Docs/s]\u001b[A\n",
            "Create embeddings:  19%|█▉        | 304/1616 [00:04<00:17, 74.08 Docs/s]\u001b[A\n",
            "Create embeddings:  20%|█▉        | 320/1616 [00:04<00:17, 73.98 Docs/s]\u001b[A\n",
            "Create embeddings:  21%|██        | 336/1616 [00:04<00:17, 74.28 Docs/s]\u001b[A\n",
            "Create embeddings:  22%|██▏       | 352/1616 [00:04<00:17, 74.13 Docs/s]\u001b[A\n",
            "Create embeddings:  23%|██▎       | 368/1616 [00:05<00:17, 71.13 Docs/s]\u001b[A\n",
            "Create embeddings:  24%|██▍       | 384/1616 [00:05<00:17, 70.66 Docs/s]\u001b[A\n",
            "Create embeddings:  25%|██▍       | 400/1616 [00:05<00:17, 71.07 Docs/s]\u001b[A\n",
            "Create embeddings:  26%|██▌       | 416/1616 [00:05<00:16, 71.08 Docs/s]\u001b[A\n",
            "Create embeddings:  27%|██▋       | 432/1616 [00:05<00:16, 70.26 Docs/s]\u001b[A\n",
            "Create embeddings:  28%|██▊       | 448/1616 [00:06<00:16, 70.79 Docs/s]\u001b[A\n",
            "Create embeddings:  29%|██▊       | 464/1616 [00:06<00:16, 70.89 Docs/s]\u001b[A\n",
            "Create embeddings:  30%|██▉       | 480/1616 [00:06<00:15, 71.24 Docs/s]\u001b[A\n",
            "Create embeddings:  31%|███       | 496/1616 [00:06<00:15, 71.98 Docs/s]\u001b[A\n",
            "Create embeddings:  32%|███▏      | 512/1616 [00:07<00:15, 71.85 Docs/s]\u001b[A\n",
            "Create embeddings:  33%|███▎      | 528/1616 [00:07<00:15, 72.22 Docs/s]\u001b[A\n",
            "Create embeddings:  34%|███▎      | 544/1616 [00:07<00:14, 72.12 Docs/s]\u001b[A\n",
            "Create embeddings:  35%|███▍      | 560/1616 [00:07<00:14, 72.40 Docs/s]\u001b[A\n",
            "Create embeddings:  36%|███▌      | 576/1616 [00:07<00:14, 72.59 Docs/s]\u001b[A\n",
            "Create embeddings:  37%|███▋      | 592/1616 [00:08<00:14, 72.25 Docs/s]\u001b[A\n",
            "Create embeddings:  38%|███▊      | 608/1616 [00:08<00:13, 72.38 Docs/s]\u001b[A\n",
            "Create embeddings:  39%|███▊      | 624/1616 [00:08<00:13, 72.78 Docs/s]\u001b[A\n",
            "Create embeddings:  40%|███▉      | 640/1616 [00:08<00:13, 72.94 Docs/s]\u001b[A\n",
            "Create embeddings:  41%|████      | 656/1616 [00:09<00:13, 72.93 Docs/s]\u001b[A\n",
            "Create embeddings:  42%|████▏     | 672/1616 [00:09<00:12, 73.19 Docs/s]\u001b[A\n",
            "Create embeddings:  43%|████▎     | 688/1616 [00:09<00:12, 73.16 Docs/s]\u001b[A\n",
            "Create embeddings:  44%|████▎     | 704/1616 [00:09<00:12, 73.07 Docs/s]\u001b[A\n",
            "Create embeddings:  45%|████▍     | 720/1616 [00:09<00:12, 72.84 Docs/s]\u001b[A\n",
            "Create embeddings:  46%|████▌     | 736/1616 [00:10<00:12, 72.37 Docs/s]\u001b[A\n",
            "Create embeddings:  47%|████▋     | 752/1616 [00:10<00:11, 72.25 Docs/s]\u001b[A\n",
            "Create embeddings:  48%|████▊     | 768/1616 [00:10<00:11, 72.02 Docs/s]\u001b[A\n",
            "Create embeddings:  49%|████▊     | 784/1616 [00:10<00:11, 72.47 Docs/s]\u001b[A\n",
            "Create embeddings:  50%|████▉     | 800/1616 [00:11<00:11, 72.24 Docs/s]\u001b[A\n",
            "Create embeddings:  50%|█████     | 816/1616 [00:11<00:11, 72.23 Docs/s]\u001b[A\n",
            "Create embeddings:  51%|█████▏    | 832/1616 [00:11<00:10, 71.85 Docs/s]\u001b[A\n",
            "Create embeddings:  52%|█████▏    | 848/1616 [00:11<00:10, 71.44 Docs/s]\u001b[A\n",
            "Create embeddings:  53%|█████▎    | 864/1616 [00:11<00:10, 72.20 Docs/s]\u001b[A\n",
            "Create embeddings:  54%|█████▍    | 880/1616 [00:12<00:10, 72.72 Docs/s]\u001b[A\n",
            "Create embeddings:  55%|█████▌    | 896/1616 [00:12<00:09, 72.74 Docs/s]\u001b[A\n",
            "Create embeddings:  56%|█████▋    | 912/1616 [00:12<00:09, 73.08 Docs/s]\u001b[A\n",
            "Create embeddings:  57%|█████▋    | 928/1616 [00:12<00:09, 73.25 Docs/s]\u001b[A\n",
            "Create embeddings:  58%|█████▊    | 944/1616 [00:13<00:09, 73.49 Docs/s]\u001b[A\n",
            "Create embeddings:  59%|█████▉    | 960/1616 [00:13<00:08, 73.26 Docs/s]\u001b[A\n",
            "Create embeddings:  60%|██████    | 976/1616 [00:13<00:08, 73.24 Docs/s]\u001b[A\n",
            "Create embeddings:  61%|██████▏   | 992/1616 [00:13<00:08, 73.25 Docs/s]\u001b[A\n",
            "Create embeddings:  62%|██████▏   | 1008/1616 [00:13<00:08, 73.30 Docs/s]\u001b[A\n",
            "Create embeddings:  63%|██████▎   | 1024/1616 [00:14<00:08, 73.28 Docs/s]\u001b[A\n",
            "Create embeddings:  64%|██████▍   | 1040/1616 [00:14<00:07, 73.26 Docs/s]\u001b[A\n",
            "Create embeddings:  65%|██████▌   | 1056/1616 [00:14<00:07, 73.30 Docs/s]\u001b[A\n",
            "Create embeddings:  66%|██████▋   | 1072/1616 [00:14<00:07, 73.50 Docs/s]\u001b[A\n",
            "Create embeddings:  67%|██████▋   | 1088/1616 [00:14<00:07, 73.59 Docs/s]\u001b[A\n",
            "Create embeddings:  68%|██████▊   | 1104/1616 [00:15<00:06, 73.73 Docs/s]\u001b[A\n",
            "Create embeddings:  69%|██████▉   | 1120/1616 [00:15<00:06, 73.49 Docs/s]\u001b[A\n",
            "Create embeddings:  70%|███████   | 1136/1616 [00:15<00:06, 73.40 Docs/s]\u001b[A\n",
            "Create embeddings:  71%|███████▏  | 1152/1616 [00:15<00:06, 73.43 Docs/s]\u001b[A\n",
            "Create embeddings:  72%|███████▏  | 1168/1616 [00:16<00:06, 73.23 Docs/s]\u001b[A\n",
            "Create embeddings:  73%|███████▎  | 1184/1616 [00:16<00:05, 73.23 Docs/s]\u001b[A\n",
            "Create embeddings:  74%|███████▍  | 1200/1616 [00:16<00:05, 73.12 Docs/s]\u001b[A\n",
            "Create embeddings:  75%|███████▌  | 1216/1616 [00:16<00:05, 73.04 Docs/s]\u001b[A\n",
            "Create embeddings:  76%|███████▌  | 1232/1616 [00:16<00:05, 73.21 Docs/s]\u001b[A\n",
            "Create embeddings:  77%|███████▋  | 1248/1616 [00:17<00:05, 73.07 Docs/s]\u001b[A\n",
            "Create embeddings:  78%|███████▊  | 1264/1616 [00:17<00:04, 73.03 Docs/s]\u001b[A\n",
            "Create embeddings:  79%|███████▉  | 1280/1616 [00:17<00:04, 72.81 Docs/s]\u001b[A\n",
            "Create embeddings:  80%|████████  | 1296/1616 [00:17<00:04, 72.85 Docs/s]\u001b[A\n",
            "Create embeddings:  81%|████████  | 1312/1616 [00:18<00:04, 72.93 Docs/s]\u001b[A\n",
            "Create embeddings:  82%|████████▏ | 1328/1616 [00:18<00:03, 73.18 Docs/s]\u001b[A\n",
            "Create embeddings:  83%|████████▎ | 1344/1616 [00:18<00:03, 73.21 Docs/s]\u001b[A\n",
            "Create embeddings:  84%|████████▍ | 1360/1616 [00:18<00:03, 72.91 Docs/s]\u001b[A\n",
            "Create embeddings:  85%|████████▌ | 1376/1616 [00:18<00:03, 72.80 Docs/s]\u001b[A\n",
            "Create embeddings:  86%|████████▌ | 1392/1616 [00:19<00:03, 72.64 Docs/s]\u001b[A\n",
            "Create embeddings:  87%|████████▋ | 1408/1616 [00:19<00:02, 72.47 Docs/s]\u001b[A\n",
            "Create embeddings:  88%|████████▊ | 1424/1616 [00:19<00:02, 72.47 Docs/s]\u001b[A\n",
            "Create embeddings:  89%|████████▉ | 1440/1616 [00:19<00:02, 72.63 Docs/s]\u001b[A\n",
            "Create embeddings:  90%|█████████ | 1456/1616 [00:20<00:02, 72.84 Docs/s]\u001b[A\n",
            "Create embeddings:  91%|█████████ | 1472/1616 [00:20<00:01, 73.01 Docs/s]\u001b[A\n",
            "Create embeddings:  92%|█████████▏| 1488/1616 [00:20<00:01, 72.37 Docs/s]\u001b[A\n",
            "Create embeddings:  93%|█████████▎| 1504/1616 [00:20<00:01, 72.31 Docs/s]\u001b[A\n",
            "Create embeddings:  94%|█████████▍| 1520/1616 [00:20<00:01, 72.21 Docs/s]\u001b[A\n",
            "Create embeddings:  95%|█████████▌| 1536/1616 [00:21<00:01, 72.42 Docs/s]\u001b[A\n",
            "Create embeddings:  96%|█████████▌| 1552/1616 [00:21<00:00, 72.26 Docs/s]\u001b[A\n",
            "Create embeddings:  97%|█████████▋| 1568/1616 [00:21<00:00, 72.18 Docs/s]\u001b[A\n",
            "Create embeddings:  98%|█████████▊| 1584/1616 [00:21<00:00, 72.31 Docs/s]\u001b[A\n",
            "Create embeddings:  99%|█████████▉| 1600/1616 [00:22<00:00, 72.34 Docs/s]\u001b[A\n",
            "Create embeddings: 100%|██████████| 1616/1616 [00:22<00:00, 73.45 Docs/s]\u001b[A\n",
            "Updating embeddings: 10000 Docs [00:45, 221.71 Docs/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step is to create a pipeline with a retriever using the DPR."
      ],
      "metadata": {
        "id": "KAkXLWZhCR-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "querying_pipeline = Pipeline()\n",
        "querying_pipeline.add_node(component=dpr_retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
        "querying_pipeline.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])\n",
        "\n",
        "n_answers = 3\n",
        "prediction = querying_pipeline.run(\n",
        "    query=query, params={\"Retriever\": {\"top_k\": 3}, \"Reader\": {\"top_k\": n_answers},  \"filters\": {\n",
        "            \"item_id\": [item_id],\n",
        "            \"split\":[\"train\"]\n",
        "        }}\n",
        ")\n",
        "pprint(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOLmzVqMVypx",
        "outputId": "1479f04c-90e3-4fab-8e16-8f37b1cdda28"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.45 Batches/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_debug': {'Reader': {'exec_time_ms': 94.22,\n",
            "                       'input': {'debug': True,\n",
            "                                 'documents': [<Document: {'content': \"I bought this via my credit union's rewards program, practically the only up to date electronic gizmo offered. I love, love it, love it. I was sans electric for four days during Sandy and I could still read and email. Not only that but getting all comfy under the covers with it is akin to the flashlight `forts' we used to make as kids. It is very easy to figure out, usable right out of the box and then, with apps, highly configurable if you are into that sort of thing which I am. The color is brilliantly crisp and clear and the audio is great although I have only listened to books on it so far, no music. I splurged on the leather cover - horrendously overpriced - and carry it with me in my purse everywhere I go.I do wish it had an app like the iPad one where you hold it up to the sky and see the constellations above you in real time but that is the only area of disappointment. There have been so many times when I am reading a book and just stop and wonder at what a truly marvelous device this is, how far we have come so quickly. I just finished a sequel to a book published a few years ago and thought when I read the first book it was a book, a book made out of paper and that, at that time, I had not envisioned I would be reading the sequel on such a magical device.So many of my friends, fellow retirees, still struggle with their computers and are baffled and helpless as soon as something goes wrong. I have told several to just replace the pc/laptop with this. A regular keyboard is nice for sending long emails but let's face it, mostly what goes through the tubes is pictures of cats, not philosophical ramblings, and the onscreen keyboard provided is totally adequate for most missives.\", 'content_type': 'text', 'score': 0.6420925456904049, 'meta': {'item_id': 'B0074BW614', 'question_id': 'c3752fc7d623fe474aa473f33c59daee', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '16ac89c6e2f1a85caaab9d7ba11e130f'}>,\n",
            "                                               <Document: {'content': \"For the price it's not bad.  The graphics are nice and the sound is good.  Wish it were a little more finger print resistant.\", 'content_type': 'text', 'score': 0.641592785200438, 'meta': {'item_id': 'B0074BW614', 'question_id': 'd68fd857b3b9d6d17b806776d0d3ecad', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '51e5206966aff7c8f03864f2a4f520e0'}>,\n",
            "                                               <Document: {'content': \"From the limited time I've had to work with my Kindle, I'm extremely pleased.  The graphics are awesome, the size and weight is just right, speed is phenomenal.  My wife is jealous and she has an iPad 2.\", 'content_type': 'text', 'score': 0.6406040836485674, 'meta': {'item_id': 'B0074BW614', 'question_id': '7e55bbbe23fe233278352936e5af66a0', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '90f04ba41b1884aeab29eb73d297733'}>],\n",
            "                                 'query': 'What is the tonal balance of these '\n",
            "                                          'headphones?',\n",
            "                                 'top_k': 3},\n",
            "                       'output': {'answers': [<Answer {'answer': '', 'type': 'extractive', 'score': 0.5494082045524029, 'context': None, 'offsets_in_document': [{'start': 0, 'end': 0}], 'offsets_in_context': [{'start': 0, 'end': 0}], 'document_ids': None, 'meta': {}}>,\n",
            "                                              <Answer {'answer': \"it's not bad\", 'type': 'extractive', 'score': 0.46279680728912354, 'context': \"For the price it's not bad.  The graphics are nice and the sound is good.  Wish it were a little more finger print resistant.\", 'offsets_in_document': [{'start': 14, 'end': 26}], 'offsets_in_context': [{'start': 14, 'end': 26}], 'document_ids': ['51e5206966aff7c8f03864f2a4f520e0'], 'meta': {'item_id': 'B0074BW614', 'question_id': 'd68fd857b3b9d6d17b806776d0d3ecad', 'split': 'train'}}>,\n",
            "                                              <Answer {'answer': 'size and weight is just right', 'type': 'extractive', 'score': 0.3900906443595886, 'context': \"indle, I'm extremely pleased.  The graphics are awesome, the size and weight is just right, speed is phenomenal.  My wife is jealous and she has an iP\", 'offsets_in_document': [{'start': 109, 'end': 138}], 'offsets_in_context': [{'start': 61, 'end': 90}], 'document_ids': ['90f04ba41b1884aeab29eb73d297733'], 'meta': {'item_id': 'B0074BW614', 'question_id': '7e55bbbe23fe233278352936e5af66a0', 'split': 'train'}}>],\n",
            "                                  'no_ans_gap': 8.877132177352905,\n",
            "                                  'query': 'What is the tonal balance of these '\n",
            "                                           'headphones?'}}},\n",
            " 'answers': [<Answer {'answer': '', 'type': 'extractive', 'score': 0.5494082045524029, 'context': None, 'offsets_in_document': [{'start': 0, 'end': 0}], 'offsets_in_context': [{'start': 0, 'end': 0}], 'document_ids': None, 'meta': {}}>,\n",
            "             <Answer {'answer': \"it's not bad\", 'type': 'extractive', 'score': 0.46279680728912354, 'context': \"For the price it's not bad.  The graphics are nice and the sound is good.  Wish it were a little more finger print resistant.\", 'offsets_in_document': [{'start': 14, 'end': 26}], 'offsets_in_context': [{'start': 14, 'end': 26}], 'document_ids': ['51e5206966aff7c8f03864f2a4f520e0'], 'meta': {'item_id': 'B0074BW614', 'question_id': 'd68fd857b3b9d6d17b806776d0d3ecad', 'split': 'train'}}>,\n",
            "             <Answer {'answer': 'size and weight is just right', 'type': 'extractive', 'score': 0.3900906443595886, 'context': \"indle, I'm extremely pleased.  The graphics are awesome, the size and weight is just right, speed is phenomenal.  My wife is jealous and she has an iP\", 'offsets_in_document': [{'start': 109, 'end': 138}], 'offsets_in_context': [{'start': 61, 'end': 90}], 'document_ids': ['90f04ba41b1884aeab29eb73d297733'], 'meta': {'item_id': 'B0074BW614', 'question_id': '7e55bbbe23fe233278352936e5af66a0', 'split': 'train'}}>],\n",
            " 'documents': [<Document: {'content': \"I bought this via my credit union's rewards program, practically the only up to date electronic gizmo offered. I love, love it, love it. I was sans electric for four days during Sandy and I could still read and email. Not only that but getting all comfy under the covers with it is akin to the flashlight `forts' we used to make as kids. It is very easy to figure out, usable right out of the box and then, with apps, highly configurable if you are into that sort of thing which I am. The color is brilliantly crisp and clear and the audio is great although I have only listened to books on it so far, no music. I splurged on the leather cover - horrendously overpriced - and carry it with me in my purse everywhere I go.I do wish it had an app like the iPad one where you hold it up to the sky and see the constellations above you in real time but that is the only area of disappointment. There have been so many times when I am reading a book and just stop and wonder at what a truly marvelous device this is, how far we have come so quickly. I just finished a sequel to a book published a few years ago and thought when I read the first book it was a book, a book made out of paper and that, at that time, I had not envisioned I would be reading the sequel on such a magical device.So many of my friends, fellow retirees, still struggle with their computers and are baffled and helpless as soon as something goes wrong. I have told several to just replace the pc/laptop with this. A regular keyboard is nice for sending long emails but let's face it, mostly what goes through the tubes is pictures of cats, not philosophical ramblings, and the onscreen keyboard provided is totally adequate for most missives.\", 'content_type': 'text', 'score': 0.6420925456904049, 'meta': {'item_id': 'B0074BW614', 'question_id': 'c3752fc7d623fe474aa473f33c59daee', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '16ac89c6e2f1a85caaab9d7ba11e130f'}>,\n",
            "               <Document: {'content': \"For the price it's not bad.  The graphics are nice and the sound is good.  Wish it were a little more finger print resistant.\", 'content_type': 'text', 'score': 0.641592785200438, 'meta': {'item_id': 'B0074BW614', 'question_id': 'd68fd857b3b9d6d17b806776d0d3ecad', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '51e5206966aff7c8f03864f2a4f520e0'}>,\n",
            "               <Document: {'content': \"From the limited time I've had to work with my Kindle, I'm extremely pleased.  The graphics are awesome, the size and weight is just right, speed is phenomenal.  My wife is jealous and she has an iPad 2.\", 'content_type': 'text', 'score': 0.6406040836485674, 'meta': {'item_id': 'B0074BW614', 'question_id': '7e55bbbe23fe233278352936e5af66a0', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '90f04ba41b1884aeab29eb73d297733'}>],\n",
            " 'no_ans_gap': 8.877132177352905,\n",
            " 'node_id': 'Reader',\n",
            " 'params': {'Reader': {'top_k': 3},\n",
            "            'Retriever': {'top_k': 3},\n",
            "            'filters': {'item_id': ['B0074BW614'], 'split': ['train']}},\n",
            " 'query': 'What is the tonal balance of these headphones?',\n",
            " 'root_node': 'Query'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_results_dpr = {}\n",
        "topk_values = [1,3,5,10,20]\n",
        "#topk_values = [1]\n",
        "for topk in topk_values:\n",
        "\teval_result = querying_pipeline.eval(labels=labels_agg,\n",
        "                                      params={\"Retriever\": {\"top_k\": topk}})\n",
        "\tmetrics = eval_result.calculate_metrics()\n",
        "\ttopk_results_dpr[topk] = {\"recall\": metrics[\"Retriever\"][\"recall_single_hit\"]}\n",
        "topk_results_dpr_df = pd.DataFrame.from_dict(topk_results_dpr, orient=\"index\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_nO2LcmpADp",
        "outputId": "e363afc3-4f4b-4df4-b838-258bb4baa156"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 71.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 71.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 68.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 72.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 61.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 68.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  2.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  4.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.18 Batches/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(topk_results_df.index, topk_results_df['recall'], label='BM25')\n",
        "plt.plot(topk_results_dpr_df.index, topk_results_dpr_df['recall'], label='Dense')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Mi5J2cIypnEM",
        "outputId": "585aa1e5-0962-4cb9-fb06-45c3f90ed1a9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7caca8260ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of the DPR retriever can be improved by fine-tuning on the target domain, see implementation [here](https://haystack.deepset.ai/tutorials/09_dpr_training).\n",
        "\n",
        "Also, the similarity search can be sped up using the FAISS library."
      ],
      "metadata": {
        "id": "5FZ2iJBBxltf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating readers\n"
      ],
      "metadata": {
        "id": "a-EnJCxcyeZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = saved_eval_result.calculate_metrics()\n",
        "print(f'Reader - F1-Score: {metrics[\"Reader\"][\"f1\"]}')\n",
        "print(f'Reader - Exact Match: {metrics[\"Reader\"][\"exact_match\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBPolyDNrskK",
        "outputId": "0d13204c-4327-4a2c-d805-ad7c845d1a5d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reader - F1-Score: 0.6870027922482301\n",
            "Reader - Exact Match: 0.5696969696969697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exact match is a much stricter metrics. But F1-score can fail to catch truly incorrect answers. Tracking both metrics is a good strategy to balance the trade-off between underestimating (EM) and overestimating\n",
        "(F1-score) model performance.\n",
        "Now in general, there are multiple valid. The overall EM and F1 scores for the model are\n",
        "then obtained by averaging over the individual scores of each question-answer pair."
      ],
      "metadata": {
        "id": "_pBmNnD3z1bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Domain adaptation\n",
        "Transformer models trained on SQUAD overfit to SQUAD data-set. That's why we see a bad EM and F1 score of the SubjQA dataset as seen above. To circumvent this problem, we can make the reader generalize better on unseen data. In other words, we can fine-tune the MiniLM model further on the SubjQA dataset.\n",
        "\n",
        "For this, we need to convert the SubjQA datset to SQUAD structure."
      ],
      "metadata": {
        "id": "xpdEoLHRBSC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.reset_option('all')\n",
        "\n",
        "#From page 201 of the book. When a product is passed, it is converted to\n",
        "#a passage in the SQUAD structure.\n",
        "def create_paragraphs(df):\n",
        "\tparagraphs = []\n",
        "\tid2context = dict(zip(df[\"review_id\"], df[\"context\"]))\n",
        "\tfor review_id, review in id2context.items():\n",
        "\t\tqas = []\n",
        "\t\t# Filter for all question-answer pairs about a specific context\n",
        "\t\treview_df = df.query(f\"review_id == '{review_id}'\")\n",
        "\t\tid2question = dict(zip(review_df[\"id\"], review_df[\"question\"]))\n",
        "\t\t# Build up the qas array\n",
        "\t\tfor qid, question in id2question.items():\n",
        "\t\t\t# Filter for a single question ID\n",
        "\t\t\tquestion_df = df.query(f\"id == '{qid}'\").to_dict(orient=\"list\")\n",
        "\t\t\tans_start_idxs = question_df[\"answers.answer_start\"][0].tolist()\n",
        "\t\t\tans_text = question_df[\"answers.text\"][0].tolist()\n",
        "\t\t\t# Fill answerable questions\n",
        "\t\t\tif len(ans_start_idxs):\n",
        "\t\t\t\tanswers = [\n",
        "\t\t\t\t{\"text\": text, \"answer_start\": answer_start}\n",
        "\t\t\t\tfor text, answer_start in zip(ans_text, ans_start_idxs)]\n",
        "\t\t\t\tis_impossible = False\n",
        "\t\t\telse:\n",
        "\t\t\t\tanswers = []\n",
        "\t\t\t\tis_impossible = True\n",
        "\t\t\t# Add question-answer pairs to qas\n",
        "\t\t\tqas.append({\"question\": question, \"id\": qid,\n",
        "\t\t\t\t\t\"is_impossible\": is_impossible, \"answers\": answers})\n",
        "\t\t\t# Add context and question-answer pairs to paragraphs\n",
        "\t\tparagraphs.append({\"qas\": qas, \"context\": review})\n",
        "\treturn paragraphs"
      ],
      "metadata": {
        "id": "9ZhKbDWk0dH9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product = dfs[\"train\"].query(\"title == 'B00001P4ZH'\")\n",
        "create_paragraphs(product)\n",
        "#This is an example of a single product in SQUAD structure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncHYYtRFFmI8",
        "outputId": "721a099e-0f70-40ce-b38f-91f45bcf70fc"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'qas': [{'question': 'How is the bass?',\n",
              "    'id': '2543d296da9766d8d17d040ecc781699',\n",
              "    'is_impossible': True,\n",
              "    'answers': []}],\n",
              "  'context': 'I have had Koss headphones in the past, Pro 4AA and QZ-99.  The Koss Portapro is portable AND has great bass response.  The work great with my Android phone and can be \"rolled up\" to be carried in my motorcycle jacket or computer bag without getting crunched.  They are very light and do not feel heavy or bear down on your ears even after listening to music with them on all day.  The sound is night and day better than any ear-bud could be and are almost as good as the Pro 4AA.  They are \"open air\" headphones so you cannot match the bass to the sealed types, but it comes close. For $32, you cannot go wrong.'},\n",
              " {'qas': [{'question': 'Is this music song have a goo bass?',\n",
              "    'id': 'd476830bf9282e2b9033e2bb44bbb995',\n",
              "    'is_impossible': False,\n",
              "    'answers': [{'text': 'Bass is weak as expected', 'answer_start': 1302},\n",
              "     {'text': 'Bass is weak as expected, even with EQ adjusted up',\n",
              "      'answer_start': 1302}]}],\n",
              "  'context': 'To anyone who hasn\\'t tried all the various types of headphones, it is important to remember exactly what these are: cheap portable on-ear headphones. They give a totally different sound then in-ears or closed design phones, but for what they are I would say they\\'re good. I currently own six pairs of phones, from stock apple earbuds to Sennheiser HD 518s. Gave my Portapros a run on both my computer\\'s sound card and mp3 player, using 256 kbps mp3s or better. The clarity is good and they\\'re very lightweight. The folding design is simple but effective. The look is certainly retro and unique, although I didn\\'t find it as comfortable as many have claimed. Earpads are *very* thin and made my ears sore after 30 minutes of listening, although this can be remedied to a point by adjusting the \"comfort zone\" feature (tightening the temple pads while loosening the ear pads). The cord seems to be an average thickness, but I wouldn\\'t get too rough with these. The steel headband adjusts smoothly and easily, just watch out that the slider doesn\\'t catch your hair. Despite the sore ears, the phones are very lightweight overall.Back to the sound: as you would expect, it\\'s good for a portable phone, but hardly earth shattering. At flat EQ the clarity is good, although the highs can sometimes be harsh. Bass is weak as expected, even with EQ adjusted up. To be fair, a portable on-ear would have a tough time comparing to the bass of an in-ear with a good seal or a pair with larger drivers. No sound isolation offered if you\\'re into that sort of thing. Cool 80s phones, though I\\'ve certainly owned better portable on-ears (Sony makes excellent phones in this category). Soundstage is very narrow and lacks body. A good value if you can get them for under thirty, otherwise I\\'d rather invest in a nicer pair of phones. If we\\'re talking about value, they\\'re a good buy compared to new stock apple buds. If you\\'re trying to compare the sound quality of this product to serious headphones, there\\'s really no comparison at all.Update: After 100 hours of burn-in time the sound has not been affected in any appreciable way. Highs are still harsh, and bass is still underwhelming. I sometimes use these as a convenience but they have been largely replaced in my collection.'},\n",
              " {'qas': [{'question': 'How is the bass?',\n",
              "    'id': '455575557886d6dfeea5aa19577e5de4',\n",
              "    'is_impossible': False,\n",
              "    'answers': [{'text': 'The only fault in the sound is the bass',\n",
              "      'answer_start': 650}]}],\n",
              "  'context': \"I have had many sub-$100 headphones from $5 Panasonic to $100 Sony, with Sennheiser HD 433, 202, PX100 II (I really wanted to like these PX100-II, they were so very well designed), and even a Grado SR60 for awhile.  And what it basically comes down to is value.  I have never heard sound as good as these headphones in the $35 range, easily the best under $75.  I can't believe they're over 25 years old.It's hard to describe how much detail these headphones bring out without making it too harsh or dull.  I listen to every type of music from classical to hip hop to electronic to country, and these headphones are suitable for all types of music.  The only fault in the sound is the bass.  It's just a *slight* bit boomy, but you get to like it after a while to be honest.The design is from the 80s as you all have probably figured out.  It could use a update but it seems like Koss has tried to perfect this formula and failed in the past.  I don't really care about the looks or the way it folds up or the fact that my hair gets caught up in it (I have very short hair, even for a male).But despite it's design flaws, it's the most comfortable headphones I have ever worn, and the best part is that it's also the best sounding pair of headphones I have ever heard under $75.If you can get over the design flaws or if sound is the most important feature of headphones for you, there is nothing even close to this at this price range.This one is an absolute GEM.  I loved these so much I ordered two of the 25th Anniversary ones for a bit more.Update: I read some reviews about the PX100-II being much improved and better sounding than the PortaPro.  Since the PX100-II is relatively new, I thought I'd give it another listen.  This time I noticed something different.  The sound is warm, mellow, and neutral, but it loses a lot of detail at the expense of these attributes.  I still prefer higher-detail Portapro, but some may prefer the more mellow sound of the PX100-II.Oh by the way the Portapro comes in the straight plug now, not the angled plug anymore.  It's supposed to be for better compatibility with the iPods and iPhones out there.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now convert the entire SubjQA data into the SQUAD structure and store it into a JSON file\n",
        "import json\n",
        "def convert_to_squad(dfs):\n",
        "\tfor split, df in dfs.items():\n",
        "\t\tsubjqa_data = {}\n",
        "\t\t# Create `paragraphs` for each product ID\n",
        "\t\tgroups = (df.groupby(\"title\").apply(create_paragraphs)\n",
        "\t\t\t\t.to_frame(name=\"paragraphs\").reset_index())\n",
        "\t\tsubjqa_data[\"data\"] = groups.to_dict(orient=\"records\")\n",
        "\t\t# Save the result to disk\n",
        "\t\twith open(f\"electronics-{split}.json\", \"w+\", encoding=\"utf-8\") as f:\n",
        "\t\t\tjson.dump(subjqa_data, f)\n",
        "convert_to_squad(dfs)"
      ],
      "metadata": {
        "id": "0pUaywQfF1ZQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_filename = \"electronics-train.json\"\n",
        "dev_filename = \"electronics-validation.json\""
      ],
      "metadata": {
        "id": "pJXSA6yJGsgy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the reader\n",
        "reader.train(data_dir=\".\", use_gpu=True, n_epochs=1, batch_size=16,\n",
        "\ttrain_filename=train_filename, dev_filename=dev_filename,save_dir=\"dom_adap_read\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21CPa4_6G5PF",
        "outputId": "cf42f1dc-c41d-4c96-f70a-c6d31bdb4dd1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPreprocessing dataset:   0%|          | 0/3 [00:00<?, ? Dicts/s]WARNING:haystack.modeling.data_handler.processor:Answer 'These earbuds are nothing special. Their best attribute is that they are cheap. The sound from them is nothing special. In comparison to my standard white IPod buds these seem to emphasize the higher frequencies. There seems to be nothing happening in the bass range with these. I don't think they are efficient enough to have much bass at all. To be fair, my IPod buds overly emphasize bass so they are not that accurate either. I also compared these to a pricy Sennheiser set that I've owned for a couple of years and let's just say there is a reason why the Sennheisers cost more.Surely these Panasonic buds are very nice to use if you think they might get damaged somehow in use as it will not break your heart to have to replace them. These might be especially useful if you only listen to talk radio or have high frequency hearing loss. If you really like to listen to the most of your music and you must wear earbuds then these are not for you.I also have to note that these are packaged in a difficult to open blister pack that required several passes with utility shears to break into. I hate to see all the plastic that has to be discarded just to get this product out of the package.Cosmetically, they are OK. They don't hurt my ears and are comfortable to me. They come with a couple of other size ear pieces if you are hard to fit. The wires take a set when folded so they are not very well-behaved and don't coil nicely and lie flat when you put them away. These will be a little bird's nest of tangled wires when you set them aside. ANSWERNOTFOUND' not contained in context.\n",
            "Example will not be converted for training/evaluation.\n",
            "Preprocessing dataset:  33%|███▎      | 1/3 [00:01<00:02,  1.36s/ Dicts]WARNING:haystack.modeling.data_handler.processor:Answer using start/end indices is '  Operation of the menus and contro' while gold label text is 'Operation of the menus and controls'.\n",
            "Example will not be converted for training/evaluation.\n",
            "WARNING:haystack.modeling.data_handler.processor:Answer using start/end indices is '  This camera performs like the pros.  Fast accurate and easy to operat' while gold label text is 'This camera performs like the pros.  Fast accurate and easy to operated'.\n",
            "Example will not be converted for training/evaluation.\n",
            "Preprocessing dataset:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/ Dicts]WARNING:haystack.modeling.data_handler.processor:Answer 'enjoy my music.  When I used my old one ear headset for music, the connection was not that good even if I put the phone in my pants pocket.  I used it on iPhone 4S and iPad 3 for music, phone calls, and audible app.  All Bluetooth controls work fine. ANSWERNOTFOUND' not contained in context.\n",
            "Example will not be converted for training/evaluation.\n",
            "WARNING:haystack.modeling.data_handler.processor:Answer 'is good.  First unit defective.  Directions are weak and limited, Net support just plain bad. Roku insists on registration, [I think SEVEN times for us] before asking dumb questions and forcing us to run from computer to TV and back.  This is a Roku 3, and apparently it's too new for them to handle. ANSWERNOTFOUND' not contained in context.\n",
            "Example will not be converted for training/evaluation.\n",
            "Preprocessing dataset: 100%|██████████| 3/3 [00:05<00:00,  1.88s/ Dicts]\n",
            "ERROR:haystack.modeling.data_handler.processor:Unable to convert 5 samples to features. Their ids are : 60-0-0, 471-0-0, 143-0-0, 83-0-0, 75-0-0\n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:02<00:00,  2.61s/ Dicts]\n",
            "ERROR:haystack.modeling.data_handler.processor:Unable to convert 5 samples to features. Their ids are : 60-0-0, 83-0-0, 471-0-0, 143-0-0, 75-0-0\n",
            "Train epoch 0/0 (Cur. train loss: 1.2124): 100%|██████████| 164/164 [01:09<00:00,  2.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We again create a pipeline with this domain adapted reader\n",
        "dom_adap_reader = FARMReader(model_name_or_path=\"dom_adap_read\")\n",
        "\n",
        "querying_pipeline = Pipeline()\n",
        "querying_pipeline.add_node(component=es_retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
        "querying_pipeline.add_node(component=dom_adap_reader, name=\"Reader\", inputs=[\"Retriever\"])\n",
        "\n",
        "#Check the quality of the QA pipeline on the labels_agg\n",
        "eval_result = querying_pipeline.eval(labels=labels_agg,\n",
        "                                     params={\"Retriever\": {\"top_k\": 3}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kjuv5hphKCoX",
        "outputId": "cb3aabfe-f131-4ee9-b99b-70f4c65322d5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:haystack.modeling.model.prediction_head:Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 54.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 63.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 71.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 65.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 66.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 64.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 41.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 62.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 56.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 52.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 53.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 43.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 60.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 59.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 67.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 45.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 38.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 51.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 50.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 57.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 71.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 55.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 49.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 48.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 46.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 42.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 44.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 39.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 36.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 40.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 47.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 37.18 Batches/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-cf59ac888c5e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                      params={\"Retriever\": {\"top_k\": 3}})\n\u001b[1;32m     11\u001b[0m \u001b[0mreader_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Reader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdom_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Reader - F1-Score: {dom_metrics[\"Reader\"][\"f1\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Reader - Exact Match: {dom_metrics[\"Reader\"][\"exact_match\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'calculate_metrics'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dom_metrics = eval_result.calculate_metrics()\n",
        "print(f'Reader - F1-Score: {dom_metrics[\"Reader\"][\"f1\"]}')\n",
        "print(f'Reader - Exact Match: {dom_metrics[\"Reader\"][\"exact_match\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04QaL2rMs-6",
        "outputId": "ff2b152c-efa5-4d51-9803-eb6b435c6c78"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reader - F1-Score: 0.26831119699159844\n",
            "Reader - Exact Match: 0.15757575757575756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think the issue is that the question and the passages are converted to vector embeddings. Need to check this."
      ],
      "metadata": {
        "id": "KZ8tc35SM6vU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Miscellaneous Information"
      ],
      "metadata": {
        "id": "iEXzspJlj_kw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHFKCnYYGr49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the environment"
      ],
      "metadata": {
        "id": "FEc5x6fEkH81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Save the requirements.txt file\n",
        "with open('requirements.txt', 'w') as f:\n",
        "    !pip freeze > requirements.txt\n",
        "\n",
        "# Download the file\n",
        "files.download('requirements.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YgsywZxnkMzJ",
        "outputId": "a8121904-0268-4052-be8f-68ea8d699fe3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8b073d7-b948-4816-83bc-4018e45785ab\", \"requirements.txt\", 10902)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7rcFfTYlkUNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}